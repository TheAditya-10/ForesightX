{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b6267e",
   "metadata": {},
   "source": [
    "# ForesightX - Stock Market Prediction Pipeline\n",
    "## ML Pipeline Stages:\n",
    "1. **Data Ingestion** - Fetch historical stock data\n",
    "2. **EDA** - Exploratory Data Analysis\n",
    "3. **Pre-processing** - Clean and prepare data\n",
    "4. **Feature Engineering & Selection** - Create and select relevant features\n",
    "5. **Model Training** - Train time-series and ML models\n",
    "6. **Model Evaluation** - Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb4539",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. DATA INGESTION\n",
    "Fetch long historical stock market data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd581c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for data ingestion\n",
    "STOCK_SYMBOL = \"AAPL\"  # Change this to any stock ticker (e.g., \"TSLA\", \"GOOGL\", \"MSFT\")\n",
    "START_DATE = \"2010-01-01\"  # Fetch as much historical data as possible\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")  # Up to today\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Stock Symbol: {STOCK_SYMBOL}\")\n",
    "print(f\"  Date Range: {START_DATE} to {END_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962bb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch historical stock data\n",
    "def fetch_stock_data(symbol, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data using yfinance\n",
    "    \n",
    "    Parameters:\n",
    "    - symbol: Stock ticker symbol (e.g., 'AAPL', 'GOOGL')\n",
    "    - start_date: Start date in 'YYYY-MM-DD' format\n",
    "    - end_date: End date in 'YYYY-MM-DD' format\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with OHLCV data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Fetching data for {symbol}...\")\n",
    "        stock = yf.Ticker(symbol)\n",
    "        \n",
    "        # Download historical data\n",
    "        df = stock.history(start=start_date, end=end_date)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"No data found for {symbol}\")\n",
    "            return None\n",
    "        \n",
    "        # Reset index to make Date a column\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "        # Get additional stock info\n",
    "        info = stock.info\n",
    "        company_name = info.get('longName', symbol)\n",
    "        sector = info.get('sector', 'N/A')\n",
    "        industry = info.get('industry', 'N/A')\n",
    "        \n",
    "        print(f\"\\nâœ“ Data fetched successfully!\")\n",
    "        print(f\"  Company: {company_name}\")\n",
    "        print(f\"  Sector: {sector}\")\n",
    "        print(f\"  Industry: {industry}\")\n",
    "        print(f\"  Total records: {len(df)}\")\n",
    "        print(f\"  Date range: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "        print(f\"  Columns: {list(df.columns)}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fetch the data\n",
    "df_raw = fetch_stock_data(STOCK_SYMBOL, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b1493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first and last few rows\n",
    "if df_raw is not None:\n",
    "    print(\"\\nðŸ“Š First 5 rows:\")\n",
    "    display(df_raw.head())\n",
    "    \n",
    "    print(\"\\nðŸ“Š Last 5 rows:\")\n",
    "    display(df_raw.tail())\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Data Summary:\")\n",
    "    print(df_raw.info())\n",
    "    \n",
    "    print(\"\\nðŸ“‰ Statistical Summary:\")\n",
    "    display(df_raw.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw data to disk for later use\n",
    "if df_raw is not None:\n",
    "    RAW_DATA_PATH = f\"../data/raw/stock_data_raw_{STOCK_SYMBOL}.csv\"\n",
    "    df_raw.to_csv(RAW_DATA_PATH, index=False)\n",
    "    print(f\"âœ“ Raw data saved to: {RAW_DATA_PATH}\")\n",
    "    print(f\"  File size: {df_raw.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fdf62",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. EXPLORATORY DATA ANALYSIS (EDA)\n",
    "Analyze patterns, trends, and characteristics of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set figure size default\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"Visualization libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a3d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data quality checks\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if df_raw is not None:\n",
    "    # Check for missing values\n",
    "    print(\"\\n1. Missing Values:\")\n",
    "    missing = df_raw.isnull().sum()\n",
    "    if missing.sum() == 0:\n",
    "        print(\"   âœ“ No missing values found!\")\n",
    "    else:\n",
    "        print(missing[missing > 0])\n",
    "    \n",
    "    # Check for duplicates\n",
    "    print(f\"\\n2. Duplicate Rows: {df_raw.duplicated().sum()}\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\n3. Data Types:\")\n",
    "    print(df_raw.dtypes)\n",
    "    \n",
    "    # Date range and frequency\n",
    "    print(f\"\\n4. Date Range:\")\n",
    "    print(f\"   Start: {df_raw['Date'].min()}\")\n",
    "    print(f\"   End: {df_raw['Date'].max()}\")\n",
    "    print(f\"   Total Days: {(df_raw['Date'].max() - df_raw['Date'].min()).days}\")\n",
    "    print(f\"   Trading Days: {len(df_raw)}\")\n",
    "    \n",
    "    # Check for zero or negative prices\n",
    "    price_cols = ['Open', 'High', 'Low', 'Close']\n",
    "    print(\"\\n5. Price Validation:\")\n",
    "    for col in price_cols:\n",
    "        if col in df_raw.columns:\n",
    "            zero_neg = (df_raw[col] <= 0).sum()\n",
    "            if zero_neg > 0:\n",
    "                print(f\"   âš  {col}: {zero_neg} zero/negative values\")\n",
    "            else:\n",
    "                print(f\"   âœ“ {col}: All positive values\")\n",
    "    \n",
    "    # Volume check\n",
    "    if 'Volume' in df_raw.columns:\n",
    "        zero_vol = (df_raw['Volume'] == 0).sum()\n",
    "        print(f\"\\n6. Zero Volume Days: {zero_vol} ({zero_vol/len(df_raw)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price movement over time\n",
    "if df_raw is not None:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Closing price over time\n",
    "    axes[0].plot(df_raw['Date'], df_raw['Close'], linewidth=1.5, color='#2E86AB', label='Close Price')\n",
    "    axes[0].set_title(f'{STOCK_SYMBOL} - Closing Price Over Time', fontsize=16, fontweight='bold')\n",
    "    axes[0].set_xlabel('Date', fontsize=12)\n",
    "    axes[0].set_ylabel('Price ($)', fontsize=12)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Volume over time\n",
    "    axes[1].bar(df_raw['Date'], df_raw['Volume'], width=2, color='#A23B72', alpha=0.6, label='Volume')\n",
    "    axes[1].set_title(f'{STOCK_SYMBOL} - Trading Volume Over Time', fontsize=16, fontweight='bold')\n",
    "    axes[1].set_xlabel('Date', fontsize=12)\n",
    "    axes[1].set_ylabel('Volume', fontsize=12)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and display key statistics\n",
    "    current_price = df_raw['Close'].iloc[-1]\n",
    "    start_price = df_raw['Close'].iloc[0]\n",
    "    total_return = ((current_price - start_price) / start_price) * 100\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Price Performance:\")\n",
    "    print(f\"   Starting Price: ${start_price:.2f}\")\n",
    "    print(f\"   Current Price: ${current_price:.2f}\")\n",
    "    print(f\"   Total Return: {total_return:.2f}%\")\n",
    "    print(f\"   All-Time High: ${df_raw['High'].max():.2f}\")\n",
    "    print(f\"   All-Time Low: ${df_raw['Low'].min():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candlestick pattern visualization (using OHLC)\n",
    "if df_raw is not None:\n",
    "    # Get last 60 days for better visibility\n",
    "    recent_data = df_raw.tail(60).copy()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    \n",
    "    # Create candlestick-like visualization\n",
    "    for idx, row in recent_data.iterrows():\n",
    "        color = '#26A69A' if row['Close'] >= row['Open'] else '#EF5350'  # Green if up, red if down\n",
    "        \n",
    "        # Draw the high-low line\n",
    "        ax.plot([row['Date'], row['Date']], [row['Low'], row['High']], \n",
    "                color=color, linewidth=1, solid_capstyle='round')\n",
    "        \n",
    "        # Draw the open-close box\n",
    "        height = abs(row['Close'] - row['Open'])\n",
    "        bottom = min(row['Open'], row['Close'])\n",
    "        ax.bar(row['Date'], height, bottom=bottom, width=0.8, color=color, alpha=0.8)\n",
    "    \n",
    "    ax.set_title(f'{STOCK_SYMBOL} - Last 60 Days Candlestick Chart', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Price ($)', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate daily statistics for recent period\n",
    "    up_days = (recent_data['Close'] > recent_data['Open']).sum()\n",
    "    down_days = (recent_data['Close'] < recent_data['Open']).sum()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Last 60 Days Statistics:\")\n",
    "    print(f\"   Up Days: {up_days} ({up_days/len(recent_data)*100:.1f}%)\")\n",
    "    print(f\"   Down Days: {down_days} ({down_days/len(recent_data)*100:.1f}%)\")\n",
    "    print(f\"   Avg Daily Range: ${recent_data['High'].mean() - recent_data['Low'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns and analyze distribution\n",
    "if df_raw is not None:\n",
    "    # Calculate daily returns\n",
    "    df_raw['Daily_Return'] = df_raw['Close'].pct_change() * 100\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Returns over time\n",
    "    axes[0].plot(df_raw['Date'], df_raw['Daily_Return'], linewidth=0.8, color='#F18F01', alpha=0.7)\n",
    "    axes[0].axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "    axes[0].set_title('Daily Returns Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Date', fontsize=12)\n",
    "    axes[0].set_ylabel('Daily Return (%)', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribution of returns\n",
    "    axes[1].hist(df_raw['Daily_Return'].dropna(), bins=100, color='#6A4C93', alpha=0.7, edgecolor='black')\n",
    "    axes[1].axvline(x=df_raw['Daily_Return'].mean(), color='red', linestyle='--', \n",
    "                    linewidth=2, label=f'Mean: {df_raw[\"Daily_Return\"].mean():.3f}%')\n",
    "    axes[1].set_title('Distribution of Daily Returns', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Daily Return (%)', fontsize=12)\n",
    "    axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical analysis of returns\n",
    "    print(\"\\nðŸ“‰ Return Statistics:\")\n",
    "    print(f\"   Mean Daily Return: {df_raw['Daily_Return'].mean():.4f}%\")\n",
    "    print(f\"   Median Daily Return: {df_raw['Daily_Return'].median():.4f}%\")\n",
    "    print(f\"   Std Deviation: {df_raw['Daily_Return'].std():.4f}%\")\n",
    "    print(f\"   Best Day: {df_raw['Daily_Return'].max():.2f}%\")\n",
    "    print(f\"   Worst Day: {df_raw['Daily_Return'].min():.2f}%\")\n",
    "    print(f\"   Positive Days: {(df_raw['Daily_Return'] > 0).sum()} ({(df_raw['Daily_Return'] > 0).sum()/len(df_raw)*100:.1f}%)\")\n",
    "    print(f\"   Negative Days: {(df_raw['Daily_Return'] < 0).sum()} ({(df_raw['Daily_Return'] < 0).sum()/len(df_raw)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c22ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving averages analysis\n",
    "if df_raw is not None:\n",
    "    # Calculate moving averages\n",
    "    df_raw['MA_20'] = df_raw['Close'].rolling(window=20).mean()\n",
    "    df_raw['MA_50'] = df_raw['Close'].rolling(window=50).mean()\n",
    "    df_raw['MA_200'] = df_raw['Close'].rolling(window=200).mean()\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(df_raw['Date'], df_raw['Close'], label='Close Price', linewidth=1.5, color='#1D3557')\n",
    "    plt.plot(df_raw['Date'], df_raw['MA_20'], label='20-Day MA', linewidth=1.5, color='#E63946', alpha=0.7)\n",
    "    plt.plot(df_raw['Date'], df_raw['MA_50'], label='50-Day MA', linewidth=1.5, color='#F77F00', alpha=0.7)\n",
    "    plt.plot(df_raw['Date'], df_raw['MA_200'], label='200-Day MA', linewidth=1.5, color='#06A77D', alpha=0.7)\n",
    "    \n",
    "    plt.title(f'{STOCK_SYMBOL} - Price with Moving Averages', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Price ($)', fontsize=12)\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Current MA positions\n",
    "    current_price = df_raw['Close'].iloc[-1]\n",
    "    current_ma20 = df_raw['MA_20'].iloc[-1]\n",
    "    current_ma50 = df_raw['MA_50'].iloc[-1]\n",
    "    current_ma200 = df_raw['MA_200'].iloc[-1]\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Current Moving Average Positions:\")\n",
    "    print(f\"   Price: ${current_price:.2f}\")\n",
    "    print(f\"   20-Day MA: ${current_ma20:.2f} ({'Above' if current_price > current_ma20 else 'Below'})\")\n",
    "    print(f\"   50-Day MA: ${current_ma50:.2f} ({'Above' if current_price > current_ma50 else 'Below'})\")\n",
    "    print(f\"   200-Day MA: ${current_ma200:.2f} ({'Above' if current_price > current_ma200 else 'Below'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility analysis\n",
    "if df_raw is not None:\n",
    "    # Calculate rolling volatility (standard deviation of returns)\n",
    "    df_raw['Volatility_30'] = df_raw['Daily_Return'].rolling(window=30).std()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Price with volatility bands\n",
    "    rolling_mean = df_raw['Close'].rolling(window=20).mean()\n",
    "    rolling_std = df_raw['Close'].rolling(window=20).std()\n",
    "    upper_band = rolling_mean + (rolling_std * 2)\n",
    "    lower_band = rolling_mean - (rolling_std * 2)\n",
    "    \n",
    "    axes[0].plot(df_raw['Date'], df_raw['Close'], label='Close Price', linewidth=1.5, color='#023047')\n",
    "    axes[0].plot(df_raw['Date'], upper_band, label='Upper Band (2Ïƒ)', linewidth=1, color='red', alpha=0.5, linestyle='--')\n",
    "    axes[0].plot(df_raw['Date'], lower_band, label='Lower Band (2Ïƒ)', linewidth=1, color='red', alpha=0.5, linestyle='--')\n",
    "    axes[0].fill_between(df_raw['Date'], upper_band, lower_band, alpha=0.1, color='gray')\n",
    "    axes[0].set_title('Bollinger Bands (20-day, 2Ïƒ)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Price ($)', fontsize=12)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Volatility over time\n",
    "    axes[1].plot(df_raw['Date'], df_raw['Volatility_30'], linewidth=1.5, color='#D62828')\n",
    "    axes[1].fill_between(df_raw['Date'], df_raw['Volatility_30'], alpha=0.3, color='#D62828')\n",
    "    axes[1].set_title('30-Day Rolling Volatility', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Date', fontsize=12)\n",
    "    axes[1].set_ylabel('Volatility (%)', fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ“Š Volatility Statistics:\")\n",
    "    print(f\"   Current 30-Day Volatility: {df_raw['Volatility_30'].iloc[-1]:.4f}%\")\n",
    "    print(f\"   Average Volatility: {df_raw['Volatility_30'].mean():.4f}%\")\n",
    "    print(f\"   Max Volatility: {df_raw['Volatility_30'].max():.4f}%\")\n",
    "    print(f\"   Min Volatility: {df_raw['Volatility_30'].min():.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c219e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis between OHLCV features\n",
    "if df_raw is not None:\n",
    "    # Select numeric columns for correlation\n",
    "    numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    corr_data = df_raw[numeric_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_data, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix - OHLCV Features', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ”— Key Correlations:\")\n",
    "    # Find strongest correlations (excluding diagonal)\n",
    "    corr_pairs = []\n",
    "    for i in range(len(corr_data.columns)):\n",
    "        for j in range(i+1, len(corr_data.columns)):\n",
    "            corr_pairs.append((corr_data.columns[i], corr_data.columns[j], corr_data.iloc[i, j]))\n",
    "    \n",
    "    corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    for feat1, feat2, corr in corr_pairs[:5]:\n",
    "        print(f\"   {feat1} <-> {feat2}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend analysis - Yearly and Monthly patterns\n",
    "if df_raw is not None:\n",
    "    # Extract year and month\n",
    "    df_raw['Year'] = pd.to_datetime(df_raw['Date']).dt.year\n",
    "    df_raw['Month'] = pd.to_datetime(df_raw['Date']).dt.month\n",
    "    df_raw['Month_Name'] = pd.to_datetime(df_raw['Date']).dt.strftime('%B')\n",
    "    df_raw['DayOfWeek'] = pd.to_datetime(df_raw['Date']).dt.dayofweek\n",
    "    df_raw['DayOfWeek_Name'] = pd.to_datetime(df_raw['Date']).dt.strftime('%A')\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # Yearly returns\n",
    "    yearly_returns = df_raw.groupby('Year')['Daily_Return'].mean() * 252  # Annualized\n",
    "    axes[0, 0].bar(yearly_returns.index, yearly_returns.values, color='#457B9D', alpha=0.8)\n",
    "    axes[0, 0].axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "    axes[0, 0].set_title('Average Annualized Return by Year', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Year')\n",
    "    axes[0, 0].set_ylabel('Return (%)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Monthly average returns\n",
    "    monthly_returns = df_raw.groupby('Month')['Daily_Return'].mean()\n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    axes[0, 1].bar(range(1, 13), monthly_returns.values, color='#E63946', alpha=0.8)\n",
    "    axes[0, 1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[0, 1].set_title('Average Daily Return by Month', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Month')\n",
    "    axes[0, 1].set_ylabel('Avg Daily Return (%)')\n",
    "    axes[0, 1].set_xticks(range(1, 13))\n",
    "    axes[0, 1].set_xticklabels(month_names, rotation=45)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Day of week returns\n",
    "    dow_returns = df_raw.groupby('DayOfWeek')['Daily_Return'].mean()\n",
    "    dow_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "    axes[1, 0].bar(range(5), dow_returns.values, color='#F77F00', alpha=0.8)\n",
    "    axes[1, 0].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[1, 0].set_title('Average Daily Return by Day of Week', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Day of Week')\n",
    "    axes[1, 0].set_ylabel('Avg Daily Return (%)')\n",
    "    axes[1, 0].set_xticks(range(5))\n",
    "    axes[1, 0].set_xticklabels(dow_names, rotation=45)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Volume by day of week\n",
    "    dow_volume = df_raw.groupby('DayOfWeek')['Volume'].mean()\n",
    "    axes[1, 1].bar(range(5), dow_volume.values, color='#06A77D', alpha=0.8)\n",
    "    axes[1, 1].set_title('Average Volume by Day of Week', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Day of Week')\n",
    "    axes[1, 1].set_ylabel('Avg Volume')\n",
    "    axes[1, 1].set_xticks(range(5))\n",
    "    axes[1, 1].set_xticklabels(dow_names, rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ“… Seasonal Patterns:\")\n",
    "    print(f\"\\n   Best Performing Month: {month_names[monthly_returns.idxmax()-1]} ({monthly_returns.max():.4f}%)\")\n",
    "    print(f\"   Worst Performing Month: {month_names[monthly_returns.idxmin()-1]} ({monthly_returns.min():.4f}%)\")\n",
    "    print(f\"\\n   Best Day of Week: {dow_names[dow_returns.idxmax()]} ({dow_returns.max():.4f}%)\")\n",
    "    print(f\"   Worst Day of Week: {dow_names[dow_returns.idxmin()]} ({dow_returns.min():.4f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of EDA findings\n",
    "if df_raw is not None:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"EDA SUMMARY - KEY INSIGHTS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Dataset Overview:\")\n",
    "    print(f\"   Total Records: {len(df_raw)}\")\n",
    "    print(f\"   Date Range: {df_raw['Date'].min().date()} to {df_raw['Date'].max().date()}\")\n",
    "    print(f\"   Features: {list(df_raw.columns)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’° Price Statistics:\")\n",
    "    print(f\"   Current Price: ${df_raw['Close'].iloc[-1]:.2f}\")\n",
    "    print(f\"   All-Time High: ${df_raw['High'].max():.2f}\")\n",
    "    print(f\"   All-Time Low: ${df_raw['Low'].min():.2f}\")\n",
    "    print(f\"   Price Range: ${df_raw['High'].max() - df_raw['Low'].min():.2f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Returns & Volatility:\")\n",
    "    print(f\"   Avg Daily Return: {df_raw['Daily_Return'].mean():.4f}%\")\n",
    "    print(f\"   Volatility (Std): {df_raw['Daily_Return'].std():.4f}%\")\n",
    "    print(f\"   Sharpe Ratio (approx): {(df_raw['Daily_Return'].mean() / df_raw['Daily_Return'].std()) * np.sqrt(252):.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Trading Activity:\")\n",
    "    print(f\"   Avg Daily Volume: {df_raw['Volume'].mean():,.0f}\")\n",
    "    print(f\"   Max Volume Day: {df_raw['Volume'].max():,.0f}\")\n",
    "    print(f\"   Positive Return Days: {(df_raw['Daily_Return'] > 0).sum()} ({(df_raw['Daily_Return'] > 0).sum()/len(df_raw)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nâœ… Data Quality:\")\n",
    "    print(f\"   Missing Values: {df_raw.isnull().sum().sum()}\")\n",
    "    print(f\"   Duplicate Rows: {df_raw.duplicated().sum()}\")\n",
    "    print(f\"   Ready for Modeling: {'Yes âœ“' if df_raw.isnull().sum().sum() == 0 else 'Needs Cleaning âš '}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2e6bc",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. PRE-PROCESSING\n",
    "Clean and prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15da027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean copy for preprocessing\n",
    "df_processed = df_raw.copy()\n",
    "\n",
    "print(\"Starting preprocessing...\")\n",
    "print(f\"Initial shape: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ded805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handle missing values (if any)\n",
    "print(\"\\n1. Checking Missing Values:\")\n",
    "missing_count = df_processed.isnull().sum().sum()\n",
    "\n",
    "if missing_count > 0:\n",
    "    print(f\"   Found {missing_count} missing values\")\n",
    "    \n",
    "    # For price columns, forward fill then backward fill\n",
    "    price_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    for col in price_columns:\n",
    "        if col in df_processed.columns:\n",
    "            before = df_processed[col].isnull().sum()\n",
    "            if before > 0:\n",
    "                df_processed[col].fillna(method='ffill', inplace=True)\n",
    "                df_processed[col].fillna(method='bfill', inplace=True)\n",
    "                print(f\"   âœ“ Filled {before} missing values in {col}\")\n",
    "    \n",
    "    # Drop rows with remaining NaN in critical columns\n",
    "    df_processed.dropna(subset=['Close'], inplace=True)\n",
    "    print(f\"   âœ“ Remaining missing values: {df_processed.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"   âœ“ No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270e616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove duplicates (if any)\n",
    "print(\"\\n2. Checking Duplicates:\")\n",
    "duplicates = df_processed.duplicated(subset=['Date']).sum()\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"   Found {duplicates} duplicate dates\")\n",
    "    df_processed.drop_duplicates(subset=['Date'], keep='first', inplace=True)\n",
    "    print(f\"   âœ“ Removed duplicates\")\n",
    "else:\n",
    "    print(\"   âœ“ No duplicates found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e57e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Sort by date to ensure chronological order\n",
    "print(\"\\n3. Ensuring Chronological Order:\")\n",
    "df_processed.sort_values('Date', inplace=True)\n",
    "df_processed.reset_index(drop=True, inplace=True)\n",
    "print(\"   âœ“ Data sorted by date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6337039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handle outliers (optional - only extreme anomalies)\n",
    "print(\"\\n4. Checking for Extreme Outliers:\")\n",
    "\n",
    "# Check for price outliers using IQR method (only flag, don't remove - price spikes are real)\n",
    "Q1 = df_processed['Close'].quantile(0.25)\n",
    "Q3 = df_processed['Close'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 3 * IQR  # Using 3*IQR for extreme outliers only\n",
    "upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "extreme_outliers = ((df_processed['Close'] < lower_bound) | (df_processed['Close'] > upper_bound)).sum()\n",
    "\n",
    "if extreme_outliers > 0:\n",
    "    print(f\"   âš  Found {extreme_outliers} extreme price outliers (NOT removing - could be real market events)\")\n",
    "    outlier_dates = df_processed[((df_processed['Close'] < lower_bound) | (df_processed['Close'] > upper_bound))]['Date'].tolist()\n",
    "    print(f\"   Dates with extreme values: {outlier_dates[:5]}\")  # Show first 5\n",
    "else:\n",
    "    print(\"   âœ“ No extreme outliers detected\")\n",
    "\n",
    "# Check for zero or negative prices (data errors)\n",
    "invalid_prices = (df_processed['Close'] <= 0).sum()\n",
    "if invalid_prices > 0:\n",
    "    print(f\"   âš  Found {invalid_prices} invalid prices (â‰¤0) - REMOVING\")\n",
    "    df_processed = df_processed[df_processed['Close'] > 0]\n",
    "    print(\"   âœ“ Invalid prices removed\")\n",
    "else:\n",
    "    print(\"   âœ“ All prices are valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f3591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Feature selection - Keep only essential columns\n",
    "print(\"\\n5. Feature Selection:\")\n",
    "print(f\"   Current columns: {list(df_processed.columns)}\")\n",
    "\n",
    "# Keep only the necessary columns for modeling\n",
    "essential_cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "# Check which essential columns exist\n",
    "available_cols = [col for col in essential_cols if col in df_processed.columns]\n",
    "df_processed = df_processed[available_cols]\n",
    "\n",
    "print(f\"   âœ“ Selected columns: {list(df_processed.columns)}\")\n",
    "print(f\"   âœ“ Removed {len(df_raw.columns) - len(df_processed.columns)} unnecessary columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nâœ“ Data Cleaning Complete!\")\n",
    "print(f\"   Initial records: {len(df_raw)}\")\n",
    "print(f\"   Final records: {len(df_processed)}\")\n",
    "print(f\"   Records removed: {len(df_raw) - len(df_processed)}\")\n",
    "print(f\"   Final shape: {df_processed.shape}\")\n",
    "print(f\"   Missing values: {df_processed.isnull().sum().sum()}\")\n",
    "print(f\"   Date range: {df_processed['Date'].min().date()} to {df_processed['Date'].max().date()}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Final Data Preview:\")\n",
    "display(df_processed.head(3))\n",
    "display(df_processed.tail(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data\n",
    "PROCESSED_DATA_PATH = f\"../data/processed/stock_data_processed_{STOCK_SYMBOL}.csv\"\n",
    "df_processed.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "\n",
    "print(f\"âœ“ Preprocessed data saved to: {PROCESSED_DATA_PATH}\")\n",
    "print(f\"  File size: {df_processed.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bae32d",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. FEATURE ENGINEERING & SELECTION\n",
    "Create and select relevant features for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature engineering dataframe\n",
    "df_features = df_processed.copy()\n",
    "\n",
    "# Ensure Date is datetime\n",
    "df_features['Date'] = pd.to_datetime(df_features['Date'])\n",
    "\n",
    "print(\"Starting Feature Engineering...\")\n",
    "print(f\"Initial shape: {df_features.shape}\")\n",
    "print(f\"Initial columns: {list(df_features.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191a3f6",
   "metadata": {},
   "source": [
    "### 4.1 LAG FEATURES\n",
    "Create lagged price and return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb20939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LAG FEATURES - Price and Returns\n",
    "print(\"\\n1. Creating Lag Features...\")\n",
    "\n",
    "# Calculate daily returns\n",
    "df_features['Return'] = df_features['Close'].pct_change()\n",
    "\n",
    "# Lagged prices (last 1, 2, 3, 5, 10 days)\n",
    "lag_periods = [1, 2, 3, 5, 10]\n",
    "for lag in lag_periods:\n",
    "    df_features[f'Price_Lag_{lag}'] = df_features['Close'].shift(lag)\n",
    "    df_features[f'Return_Lag_{lag}'] = df_features['Return'].shift(lag)\n",
    "    df_features[f'Volume_Lag_{lag}'] = df_features['Volume'].shift(lag)\n",
    "\n",
    "# Price changes\n",
    "df_features['Price_Change_1d'] = df_features['Close'] - df_features['Close'].shift(1)\n",
    "df_features['Price_Change_5d'] = df_features['Close'] - df_features['Close'].shift(5)\n",
    "\n",
    "print(f\"   âœ“ Created {len(lag_periods) * 3} lag features\")\n",
    "print(f\"   âœ“ Created 2 price change features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb0e63",
   "metadata": {},
   "source": [
    "### 4.2 TECHNICAL INDICATORS\n",
    "Moving averages, momentum, and trend indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcaa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MOVING AVERAGES - SMA and EMA\n",
    "print(\"\\n2. Creating Moving Average Features...\")\n",
    "\n",
    "# Simple Moving Averages\n",
    "sma_windows = [5, 10, 20, 50, 200]\n",
    "for window in sma_windows:\n",
    "    df_features[f'SMA_{window}'] = df_features['Close'].rolling(window=window).mean()\n",
    "    # Distance from SMA (price relative to MA)\n",
    "    df_features[f'Price_to_SMA_{window}'] = df_features['Close'] / df_features[f'SMA_{window}'] - 1\n",
    "\n",
    "# Exponential Moving Averages\n",
    "ema_windows = [12, 26, 50]\n",
    "for window in ema_windows:\n",
    "    df_features[f'EMA_{window}'] = df_features['Close'].ewm(span=window, adjust=False).mean()\n",
    "    df_features[f'Price_to_EMA_{window}'] = df_features['Close'] / df_features[f'EMA_{window}'] - 1\n",
    "\n",
    "# Moving average crossovers (signals)\n",
    "df_features['SMA_Cross_50_200'] = (df_features['SMA_50'] > df_features['SMA_200']).astype(int)\n",
    "df_features['EMA_Cross_12_26'] = (df_features['EMA_12'] > df_features['EMA_26']).astype(int)\n",
    "\n",
    "print(f\"   âœ“ Created {len(sma_windows)} SMA features\")\n",
    "print(f\"   âœ“ Created {len(ema_windows)} EMA features\")\n",
    "print(f\"   âœ“ Created crossover signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RSI (Relative Strength Index)\n",
    "print(\"\\n3. Creating RSI Features...\")\n",
    "\n",
    "def calculate_rsi(data, window=14):\n",
    "    \"\"\"Calculate RSI indicator\"\"\"\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "# RSI with different windows\n",
    "rsi_windows = [14, 21]\n",
    "for window in rsi_windows:\n",
    "    df_features[f'RSI_{window}'] = calculate_rsi(df_features['Close'], window)\n",
    "    # RSI signals\n",
    "    df_features[f'RSI_{window}_Oversold'] = (df_features[f'RSI_{window}'] < 30).astype(int)\n",
    "    df_features[f'RSI_{window}_Overbought'] = (df_features[f'RSI_{window}'] > 70).astype(int)\n",
    "\n",
    "print(f\"   âœ“ Created RSI features for {len(rsi_windows)} periods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. MACD (Moving Average Convergence Divergence)\n",
    "print(\"\\n4. Creating MACD Features...\")\n",
    "\n",
    "# MACD components\n",
    "df_features['MACD'] = df_features['EMA_12'] - df_features['EMA_26']\n",
    "df_features['MACD_Signal'] = df_features['MACD'].ewm(span=9, adjust=False).mean()\n",
    "df_features['MACD_Histogram'] = df_features['MACD'] - df_features['MACD_Signal']\n",
    "\n",
    "# MACD signals\n",
    "df_features['MACD_Bullish'] = (df_features['MACD'] > df_features['MACD_Signal']).astype(int)\n",
    "df_features['MACD_Crossover'] = ((df_features['MACD'] > df_features['MACD_Signal']) & \n",
    "                                  (df_features['MACD'].shift(1) <= df_features['MACD_Signal'].shift(1))).astype(int)\n",
    "\n",
    "print(\"   âœ“ Created MACD line, signal, and histogram\")\n",
    "print(\"   âœ“ Created MACD crossover signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0381cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. BOLLINGER BANDS\n",
    "print(\"\\n5. Creating Bollinger Bands Features...\")\n",
    "\n",
    "# Bollinger Bands (20-day, 2 std)\n",
    "window = 20\n",
    "df_features['BB_Middle'] = df_features['Close'].rolling(window=window).mean()\n",
    "df_features['BB_Std'] = df_features['Close'].rolling(window=window).std()\n",
    "df_features['BB_Upper'] = df_features['BB_Middle'] + (2 * df_features['BB_Std'])\n",
    "df_features['BB_Lower'] = df_features['BB_Middle'] - (2 * df_features['BB_Std'])\n",
    "\n",
    "# Bollinger Band width and position\n",
    "df_features['BB_Width'] = (df_features['BB_Upper'] - df_features['BB_Lower']) / df_features['BB_Middle']\n",
    "df_features['BB_Position'] = (df_features['Close'] - df_features['BB_Lower']) / (df_features['BB_Upper'] - df_features['BB_Lower'])\n",
    "\n",
    "# Bollinger Band signals\n",
    "df_features['BB_Above_Upper'] = (df_features['Close'] > df_features['BB_Upper']).astype(int)\n",
    "df_features['BB_Below_Lower'] = (df_features['Close'] < df_features['BB_Lower']).astype(int)\n",
    "\n",
    "print(\"   âœ“ Created Bollinger Bands (upper, middle, lower)\")\n",
    "print(\"   âœ“ Created BB width and position metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95247f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ATR (Average True Range) - Volatility measure\n",
    "print(\"\\n6. Creating ATR Features...\")\n",
    "\n",
    "def calculate_atr(high, low, close, window=14):\n",
    "    \"\"\"Calculate Average True Range\"\"\"\n",
    "    high_low = high - low\n",
    "    high_close = np.abs(high - close.shift())\n",
    "    low_close = np.abs(low - close.shift())\n",
    "    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    atr = true_range.rolling(window=window).mean()\n",
    "    return atr\n",
    "\n",
    "# ATR with different windows\n",
    "atr_windows = [14, 21]\n",
    "for window in atr_windows:\n",
    "    df_features[f'ATR_{window}'] = calculate_atr(df_features['High'], df_features['Low'], \n",
    "                                                   df_features['Close'], window)\n",
    "    # Normalized ATR (as % of price)\n",
    "    df_features[f'ATR_{window}_Pct'] = (df_features[f'ATR_{window}'] / df_features['Close']) * 100\n",
    "\n",
    "print(f\"   âœ“ Created ATR features for {len(atr_windows)} periods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07247e46",
   "metadata": {},
   "source": [
    "### 4.3 VOLATILITY FEATURES\n",
    "Rolling standard deviation and realized volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149644c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. VOLATILITY FEATURES\n",
    "print(\"\\n7. Creating Volatility Features...\")\n",
    "\n",
    "# Rolling standard deviation of returns\n",
    "vol_windows = [5, 10, 20, 30]\n",
    "for window in vol_windows:\n",
    "    df_features[f'Volatility_{window}d'] = df_features['Return'].rolling(window=window).std()\n",
    "    # Annualized volatility\n",
    "    df_features[f'Volatility_{window}d_Ann'] = df_features[f'Volatility_{window}d'] * np.sqrt(252)\n",
    "\n",
    "# Realized volatility (intraday range)\n",
    "df_features['Realized_Vol'] = (df_features['High'] - df_features['Low']) / df_features['Close']\n",
    "\n",
    "# Parkinson's volatility (uses high-low range)\n",
    "df_features['Parkinson_Vol'] = np.sqrt((1 / (4 * np.log(2))) * \n",
    "                                        ((np.log(df_features['High'] / df_features['Low'])) ** 2))\n",
    "\n",
    "# Volatility change\n",
    "df_features['Volatility_Change'] = df_features['Volatility_20d'].pct_change()\n",
    "\n",
    "print(f\"   âœ“ Created rolling volatility for {len(vol_windows)} windows\")\n",
    "print(\"   âœ“ Created realized and Parkinson volatility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b41ba2",
   "metadata": {},
   "source": [
    "### 4.4 VOLUME FEATURES\n",
    "Volume-based indicators and VWAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957548e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. VOLUME FEATURES\n",
    "print(\"\\n8. Creating Volume Features...\")\n",
    "\n",
    "# Volume change\n",
    "df_features['Volume_Change'] = df_features['Volume'].pct_change()\n",
    "df_features['Volume_Change_5d'] = df_features['Volume'].pct_change(periods=5)\n",
    "\n",
    "# Volume moving averages\n",
    "vol_ma_windows = [5, 20, 50]\n",
    "for window in vol_ma_windows:\n",
    "    df_features[f'Volume_MA_{window}'] = df_features['Volume'].rolling(window=window).mean()\n",
    "    # Volume ratio to moving average\n",
    "    df_features[f'Volume_Ratio_{window}'] = df_features['Volume'] / df_features[f'Volume_MA_{window}']\n",
    "\n",
    "# VWAP (Volume Weighted Average Price) - approximation using daily data\n",
    "df_features['Typical_Price'] = (df_features['High'] + df_features['Low'] + df_features['Close']) / 3\n",
    "df_features['VWAP_20'] = (df_features['Typical_Price'] * df_features['Volume']).rolling(window=20).sum() / \\\n",
    "                          df_features['Volume'].rolling(window=20).sum()\n",
    "df_features['Price_to_VWAP'] = df_features['Close'] / df_features['VWAP_20'] - 1\n",
    "\n",
    "# On-Balance Volume (OBV)\n",
    "df_features['OBV'] = (np.sign(df_features['Close'].diff()) * df_features['Volume']).fillna(0).cumsum()\n",
    "\n",
    "# Volume-Price Trend\n",
    "df_features['VPT'] = (df_features['Volume'] * df_features['Return']).cumsum()\n",
    "\n",
    "print(f\"   âœ“ Created volume change and ratio features\")\n",
    "print(\"   âœ“ Created VWAP and price-to-VWAP\")\n",
    "print(\"   âœ“ Created OBV and VPT indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8df388",
   "metadata": {},
   "source": [
    "### 4.5 CALENDAR FEATURES\n",
    "Time-based features: day of week, month, holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce146fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. CALENDAR FEATURES\n",
    "print(\"\\n9. Creating Calendar Features...\")\n",
    "\n",
    "# Day of week (0=Monday, 4=Friday)\n",
    "df_features['Day_of_Week'] = df_features['Date'].dt.dayofweek\n",
    "df_features['Is_Monday'] = (df_features['Day_of_Week'] == 0).astype(int)\n",
    "df_features['Is_Friday'] = (df_features['Day_of_Week'] == 4).astype(int)\n",
    "\n",
    "# Month\n",
    "df_features['Month'] = df_features['Date'].dt.month\n",
    "df_features['Quarter'] = df_features['Date'].dt.quarter\n",
    "\n",
    "# Day of month\n",
    "df_features['Day_of_Month'] = df_features['Date'].dt.day\n",
    "df_features['Is_Month_Start'] = (df_features['Day_of_Month'] <= 5).astype(int)\n",
    "df_features['Is_Month_End'] = (df_features['Day_of_Month'] >= 25).astype(int)\n",
    "\n",
    "# Week of year\n",
    "df_features['Week_of_Year'] = df_features['Date'].dt.isocalendar().week\n",
    "\n",
    "# Holiday proximity (simplified - near major US holidays)\n",
    "# Note: For production, use proper holiday calendar library\n",
    "df_features['Is_January'] = (df_features['Month'] == 1).astype(int)  # New Year effect\n",
    "df_features['Is_December'] = (df_features['Month'] == 12).astype(int)  # Year-end effect\n",
    "\n",
    "# Days since start of year (handle timezone-aware dates)\n",
    "year_starts = pd.to_datetime(df_features['Date'].dt.year.astype(str) + '-01-01')\n",
    "# Remove timezone info if present\n",
    "if df_features['Date'].dt.tz is not None:\n",
    "    year_starts = year_starts.dt.tz_localize(df_features['Date'].dt.tz)\n",
    "df_features['Days_Since_Year_Start'] = (df_features['Date'] - year_starts).dt.days\n",
    "\n",
    "print(\"   âœ“ Created day of week features\")\n",
    "print(\"   âœ“ Created month and quarter features\")\n",
    "print(\"   âœ“ Created holiday proximity indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beef75d",
   "metadata": {},
   "source": [
    "### 4.6 ADDITIONAL FEATURES\n",
    "Price patterns, momentum, and other derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. MOMENTUM AND PRICE PATTERNS\n",
    "print(\"\\n10. Creating Momentum & Pattern Features...\")\n",
    "\n",
    "# Rate of Change (ROC)\n",
    "roc_periods = [5, 10, 20]\n",
    "for period in roc_periods:\n",
    "    df_features[f'ROC_{period}'] = ((df_features['Close'] - df_features['Close'].shift(period)) / \n",
    "                                     df_features['Close'].shift(period)) * 100\n",
    "\n",
    "# Momentum\n",
    "df_features['Momentum_10'] = df_features['Close'] - df_features['Close'].shift(10)\n",
    "\n",
    "# Price range features\n",
    "df_features['High_Low_Range'] = df_features['High'] - df_features['Low']\n",
    "df_features['High_Low_Range_Pct'] = (df_features['High_Low_Range'] / df_features['Close']) * 100\n",
    "\n",
    "# Body size (Open-Close range)\n",
    "df_features['Body_Size'] = abs(df_features['Close'] - df_features['Open'])\n",
    "df_features['Body_Size_Pct'] = (df_features['Body_Size'] / df_features['Close']) * 100\n",
    "\n",
    "# Upper/Lower shadows\n",
    "df_features['Upper_Shadow'] = df_features['High'] - df_features[['Open', 'Close']].max(axis=1)\n",
    "df_features['Lower_Shadow'] = df_features[['Open', 'Close']].min(axis=1) - df_features['Low']\n",
    "\n",
    "# Bullish/Bearish candle\n",
    "df_features['Is_Bullish'] = (df_features['Close'] > df_features['Open']).astype(int)\n",
    "\n",
    "# Gap up/down\n",
    "df_features['Gap'] = df_features['Open'] - df_features['Close'].shift(1)\n",
    "df_features['Gap_Pct'] = (df_features['Gap'] / df_features['Close'].shift(1)) * 100\n",
    "\n",
    "# Consecutive up/down days\n",
    "df_features['Price_Direction'] = np.sign(df_features['Close'] - df_features['Close'].shift(1))\n",
    "df_features['Consecutive_Up'] = df_features.groupby((df_features['Price_Direction'] != \n",
    "                                  df_features['Price_Direction'].shift()).cumsum())['Price_Direction'].cumsum()\n",
    "\n",
    "print(\"   âœ“ Created ROC and momentum features\")\n",
    "print(\"   âœ“ Created candlestick pattern features\")\n",
    "print(\"   âœ“ Created gap and direction features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. TARGET VARIABLE - Next day's return (for prediction)\n",
    "print(\"\\n11. Creating Target Variable...\")\n",
    "\n",
    "# Next day's return (what we want to predict)\n",
    "df_features['Target_Return'] = df_features['Return'].shift(-1)\n",
    "\n",
    "# Classification target (Up/Down)\n",
    "df_features['Target_Direction'] = (df_features['Target_Return'] > 0).astype(int)\n",
    "\n",
    "# Multi-class target (Strong Down, Down, Flat, Up, Strong Up)\n",
    "df_features['Target_Class'] = pd.cut(df_features['Target_Return'], \n",
    "                                      bins=[-np.inf, -0.02, -0.005, 0.005, 0.02, np.inf],\n",
    "                                      labels=[0, 1, 2, 3, 4])  # 0=Strong Down, 4=Strong Up\n",
    "\n",
    "print(\"   âœ“ Created regression target (next day return)\")\n",
    "print(\"   âœ“ Created binary classification target (up/down)\")\n",
    "print(\"   âœ“ Created multi-class target (5 classes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4cf13",
   "metadata": {},
   "source": [
    "### 4.7 FEATURE SUMMARY & CLEANUP\n",
    "Remove NaN values and display feature statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Shape:\")\n",
    "print(f\"   Before feature engineering: {df_processed.shape}\")\n",
    "print(f\"   After feature engineering: {df_features.shape}\")\n",
    "print(f\"   Total features created: {df_features.shape[1] - df_processed.shape[1]}\")\n",
    "\n",
    "print(f\"\\nðŸ”¢ Feature Categories:\")\n",
    "feature_categories = {\n",
    "    'Lag Features': len([col for col in df_features.columns if 'Lag' in col]),\n",
    "    'Moving Averages': len([col for col in df_features.columns if 'MA' in col or 'EMA' in col]),\n",
    "    'Technical Indicators': len([col for col in df_features.columns if any(x in col for x in ['RSI', 'MACD', 'BB_'])]),\n",
    "    'Volatility': len([col for col in df_features.columns if 'Volatility' in col or 'ATR' in col or 'Vol' in col]),\n",
    "    'Volume': len([col for col in df_features.columns if 'Volume' in col or 'VWAP' in col or 'OBV' in col or 'VPT' in col]),\n",
    "    'Calendar': len([col for col in df_features.columns if any(x in col for x in ['Day', 'Month', 'Week', 'Quarter', 'Is_'])]),\n",
    "    'Price Patterns': len([col for col in df_features.columns if any(x in col for x in ['ROC', 'Momentum', 'Gap', 'Shadow', 'Body'])]),\n",
    "    'Target': len([col for col in df_features.columns if 'Target' in col])\n",
    "}\n",
    "\n",
    "for category, count in feature_categories.items():\n",
    "    print(f\"   {category}: {count} features\")\n",
    "\n",
    "print(f\"\\nâš  Missing Values:\")\n",
    "missing = df_features.isnull().sum().sum()\n",
    "print(f\"   Total: {missing} ({missing / (df_features.shape[0] * df_features.shape[1]) * 100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Feature List (first 20):\")\n",
    "print(f\"   {list(df_features.columns[:20])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b101eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values created by rolling calculations\n",
    "print(\"\\nðŸ§¹ Cleaning up missing values...\")\n",
    "\n",
    "# Display rows with NaN before cleanup\n",
    "print(f\"   Rows with any NaN: {df_features.isnull().any(axis=1).sum()}\")\n",
    "\n",
    "# Drop rows with NaN values (typically at the start due to rolling windows)\n",
    "# Keep the target column for now\n",
    "df_clean = df_features.dropna(subset=[col for col in df_features.columns if 'Target' not in col])\n",
    "\n",
    "print(f\"   Rows after removing NaN: {len(df_clean)}\")\n",
    "print(f\"   Data retained: {len(df_clean) / len(df_features) * 100:.1f}%\")\n",
    "\n",
    "# Display sample (check which columns are available)\n",
    "print(\"\\nðŸ“‹ Sample of engineered features:\")\n",
    "sample_cols = ['Date', 'Close', 'Return', 'SMA_20', 'RSI_14', 'MACD', 'Volatility_20d', 'Volume_Ratio_20']\n",
    "# Add Target_Return if it exists\n",
    "if 'Target_Return' in df_clean.columns:\n",
    "    sample_cols.append('Target_Return')\n",
    "display(df_clean[sample_cols].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation analysis (select top features)\n",
    "print(\"\\nðŸ”— Feature Correlation with Target...\")\n",
    "\n",
    "# Calculate correlation with target\n",
    "target_corr = df_clean.select_dtypes(include=[np.number]).corr()['Target_Return'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š Top 20 Features Correlated with Target Return:\")\n",
    "print(target_corr[1:21])  # Skip Target_Return itself\n",
    "\n",
    "# Visualize top correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = target_corr[1:16]  # Top 15\n",
    "plt.barh(range(len(top_features)), top_features.values, color='steelblue')\n",
    "plt.yticks(range(len(top_features)), top_features.index)\n",
    "plt.xlabel('Absolute Correlation with Target Return', fontsize=12)\n",
    "plt.title('Top 15 Features by Correlation with Target', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature-engineered dataset\n",
    "FEATURES_DATA_PATH = f\"../data/processed/stock_features_{STOCK_SYMBOL}.csv\"\n",
    "df_clean.to_csv(FEATURES_DATA_PATH, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Feature engineering complete!\")\n",
    "print(f\"âœ“ Engineered data saved to: {FEATURES_DATA_PATH}\")\n",
    "print(f\"  Final dataset shape: {df_clean.shape}\")\n",
    "print(f\"  Total features: {df_clean.shape[1]}\")\n",
    "print(f\"  File size: {df_clean.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "# Note for future steps\n",
    "print(\"\\nðŸ“ Note:\")\n",
    "print(\"   - Fundamental ratios (PE, PB, EPS) require additional data sources\")\n",
    "print(\"   - Sentiment scores require news/social media API integration\")\n",
    "print(\"   - Macro indicators require economic data feeds\")\n",
    "print(\"   - These can be added in production pipeline with appropriate APIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8142fa",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. MODEL TRAINING\n",
    "Train time-series and ML models on historical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f3b94",
   "metadata": {},
   "source": [
    "### ðŸ“Š Model Training Strategy\n",
    "\n",
    "**Ensemble Approach**: We'll build multiple models and combine their predictions for robust forecasting\n",
    "\n",
    "**Model Suite:**\n",
    "1. **Baseline Classical Models** - Statistical foundations\n",
    "   - ARIMA/SARIMAX for trend & seasonality\n",
    "   - Prophet for interpretable seasonality baseline\n",
    "\n",
    "2. **ML Models** - Feature-based learning\n",
    "   - XGBoost/LightGBM on engineered features\n",
    "   - MLP (Multi-Layer Perceptron) on window features\n",
    "\n",
    "3. **Deep Time-Series Models** - Sequential learning\n",
    "   - LSTM/GRU for sequence modeling\n",
    "   - Temporal Fusion Transformer (TFT) for interpretability\n",
    "\n",
    "4. **Probabilistic Models** - Uncertainty quantification\n",
    "   - Quantile regression for prediction intervals\n",
    "   - Bayesian approaches for confidence estimation\n",
    "\n",
    "5. **Ensemble** - Combined intelligence\n",
    "   - Weighted blend based on validation performance\n",
    "   - Stacking with meta-learner\n",
    "\n",
    "**Training Approach:**\n",
    "- Time-series walk-forward validation (non-leaky splits)\n",
    "- Separate test set for final evaluation\n",
    "- Transaction costs & slippage simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430cdd29",
   "metadata": {},
   "source": [
    "### 5.1 Data Preparation & Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature-engineered data\n",
    "print(\"ðŸ“‚ Loading feature-engineered data...\")\n",
    "FEATURES_DATA_PATH = f\"../data/processed/stock_features_{STOCK_SYMBOL}.csv\"\n",
    "df_features = pd.read_csv(FEATURES_DATA_PATH)\n",
    "\n",
    "# Convert Date to datetime if needed\n",
    "if 'Date' in df_features.columns:\n",
    "    df_features['Date'] = pd.to_datetime(df_features['Date'])\n",
    "    date_col = 'Date'\n",
    "elif 'date' in df_features.columns:\n",
    "    df_features['date'] = pd.to_datetime(df_features['date'])\n",
    "    date_col = 'date'\n",
    "else:\n",
    "    raise ValueError(\"No date column found in the dataset\")\n",
    "\n",
    "print(f\"   âœ“ Loaded {len(df_features)} rows\")\n",
    "print(f\"   âœ“ Features: {df_features.shape[1]} columns\")\n",
    "print(f\"   âœ“ Date range: {df_features[date_col].min()} to {df_features[date_col].max()}\")\n",
    "\n",
    "# Time-series split: 70% train, 15% validation, 15% test\n",
    "# Using chronological split to prevent data leakage\n",
    "df_sorted = df_features.sort_values(date_col).reset_index(drop=True)\n",
    "\n",
    "# Calculate split indices\n",
    "n = len(df_sorted)\n",
    "train_end = int(n * 0.70)\n",
    "val_end = int(n * 0.85)\n",
    "\n",
    "# Split data\n",
    "train_df = df_sorted.iloc[:train_end].copy()\n",
    "val_df = df_sorted.iloc[train_end:val_end].copy()\n",
    "test_df = df_sorted.iloc[val_end:].copy()\n",
    "\n",
    "print(\"\\nðŸ“Š Data Split Summary:\")\n",
    "print(f\"   Total samples: {n}\")\n",
    "print(f\"   Train: {len(train_df)} ({len(train_df)/n*100:.1f}%) | {train_df[date_col].min()} to {train_df[date_col].max()}\")\n",
    "print(f\"   Val:   {len(val_df)} ({len(val_df)/n*100:.1f}%) | {val_df[date_col].min()} to {val_df[date_col].max()}\")\n",
    "print(f\"   Test:  {len(test_df)} ({len(test_df)/n*100:.1f}%) | {test_df[date_col].min()} to {test_df[date_col].max()}\")\n",
    "\n",
    "# Define target and feature columns\n",
    "target_col = 'Close'  # Price prediction target\n",
    "feature_cols = [col for col in df_sorted.columns if col not in [date_col, 'Ticker', 'ticker', 'Target_Return', 'Target_Direction', 'Target_Class']]\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Target: {target_col}\")\n",
    "print(f\"ðŸ“ˆ Features: {len(feature_cols)} columns\")\n",
    "print(f\"   Excluding: Date, Ticker, Target variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aff02f",
   "metadata": {},
   "source": [
    "### 5.2 Baseline Classical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e9255",
   "metadata": {},
   "source": [
    "#### 5.2.1 ARIMA/SARIMAX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1973e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ðŸ”„ Training SARIMAX Model...\")\n",
    "\n",
    "# Check stationarity\n",
    "adf_result = adfuller(train_df[target_col].dropna())\n",
    "print(f\"   ADF Statistic: {adf_result[0]:.4f}\")\n",
    "print(f\"   p-value: {adf_result[1]:.4f}\")\n",
    "print(f\"   Stationary: {'Yes' if adf_result[1] < 0.05 else 'No'}\")\n",
    "\n",
    "# SARIMAX(p,d,q)(P,D,Q,s) - using auto-selected parameters\n",
    "# For stock prices: (1,1,1)(1,1,1,5) as starting point\n",
    "try:\n",
    "    sarimax_model = SARIMAX(\n",
    "        train_df[target_col],\n",
    "        order=(1, 1, 1),\n",
    "        seasonal_order=(1, 1, 1, 5),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    \n",
    "    sarimax_fit = sarimax_model.fit(disp=False, maxiter=200)\n",
    "    \n",
    "    # Validation predictions\n",
    "    val_pred_sarimax = sarimax_fit.forecast(steps=len(val_df))\n",
    "    \n",
    "    print(\"âœ… SARIMAX model trained successfully\")\n",
    "    print(f\"   AIC: {sarimax_fit.aic:.2f}\")\n",
    "    print(f\"   BIC: {sarimax_fit.bic:.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ SARIMAX training failed: {str(e)}\")\n",
    "    val_pred_sarimax = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef13ac2",
   "metadata": {},
   "source": [
    "#### 5.2.2 Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "print(\"ðŸ”„ Training Prophet Model...\")\n",
    "\n",
    "try:\n",
    "    # Prepare data for Prophet (requires 'ds' and 'y' columns)\n",
    "    # Convert timezone-aware datetime to timezone-naive\n",
    "    prophet_train = train_df[[date_col, target_col]].copy()\n",
    "    prophet_train[date_col] = pd.to_datetime(prophet_train[date_col]).dt.tz_localize(None)\n",
    "    prophet_train = prophet_train.rename(columns={date_col: 'ds', target_col: 'y'})\n",
    "    \n",
    "    prophet_val = val_df[[date_col, target_col]].copy()\n",
    "    prophet_val[date_col] = pd.to_datetime(prophet_val[date_col]).dt.tz_localize(None)\n",
    "    prophet_val = prophet_val.rename(columns={date_col: 'ds', target_col: 'y'})\n",
    "    \n",
    "    # Initialize and fit Prophet\n",
    "    prophet_model = Prophet(\n",
    "        daily_seasonality=True,\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=True,\n",
    "        changepoint_prior_scale=0.05,\n",
    "        seasonality_prior_scale=10.0\n",
    "    )\n",
    "    \n",
    "    prophet_model.fit(prophet_train)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    future_val = prophet_val[['ds']]\n",
    "    forecast_val = prophet_model.predict(future_val)\n",
    "    val_pred_prophet = forecast_val['yhat'].values\n",
    "    \n",
    "    print(\"âœ… Prophet model trained successfully\")\n",
    "    print(f\"   Changepoints: {len(prophet_model.changepoints)}\")\n",
    "    print(f\"   Seasonality components: daily, weekly, yearly\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Prophet training failed: {str(e)}\")\n",
    "    val_pred_prophet = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281e57d7",
   "metadata": {},
   "source": [
    "### 5.3 Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ML features (exclude non-numeric columns)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numeric features\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "ml_features = [f for f in numeric_features if f != target_col]\n",
    "\n",
    "print(f\"ðŸ“Š ML Features: {len(ml_features)} columns\")\n",
    "\n",
    "# Prepare train, val, test sets\n",
    "X_train = train_df[ml_features].fillna(method='ffill').fillna(0)\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_val = val_df[ml_features].fillna(method='ffill').fillna(0)\n",
    "y_val = val_df[target_col]\n",
    "\n",
    "X_test = test_df[ml_features].fillna(method='ffill').fillna(0)\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ… Data prepared for ML models\")\n",
    "print(f\"   Train shape: {X_train_scaled.shape}\")\n",
    "print(f\"   Val shape: {X_val_scaled.shape}\")\n",
    "print(f\"   Test shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10395c5d",
   "metadata": {},
   "source": [
    "#### 5.3.1 XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c23d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "print(\"ðŸ”„ Training XGBoost Model...\")\n",
    "\n",
    "# XGBoost parameters\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist',\n",
    "    'early_stopping_rounds': 20\n",
    "}\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "xgb_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "val_pred_xgb = xgb_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_val, val_pred_xgb))\n",
    "mae = mean_absolute_error(y_val, val_pred_xgb)\n",
    "\n",
    "print(\"âœ… XGBoost model trained successfully\")\n",
    "print(f\"   Best iteration: {xgb_model.best_iteration}\")\n",
    "print(f\"   Val RMSE: ${rmse:.2f}\")\n",
    "print(f\"   Val MAE: ${mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd2f16",
   "metadata": {},
   "source": [
    "#### 5.3.2 LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43418cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "print(\"ðŸ”„ Training LightGBM Model...\")\n",
    "\n",
    "# LightGBM parameters\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Train LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "lgb_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    callbacks=[lgb.early_stopping(20), lgb.log_evaluation(0)]\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "val_pred_lgb = lgb_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_val, val_pred_lgb))\n",
    "mae = mean_absolute_error(y_val, val_pred_lgb)\n",
    "\n",
    "print(\"âœ… LightGBM model trained successfully\")\n",
    "print(f\"   Best iteration: {lgb_model.best_iteration_}\")\n",
    "print(f\"   Val RMSE: ${rmse:.2f}\")\n",
    "print(f\"   Val MAE: ${mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435e5a7",
   "metadata": {},
   "source": [
    "#### 5.3.3 LightGBM Quantile Regression (Probabilistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Training LightGBM Quantile Regression Models...\")\n",
    "\n",
    "# Train models for different quantiles (prediction intervals)\n",
    "quantiles = [0.1, 0.5, 0.9]  # 10th, 50th (median), 90th percentiles\n",
    "quantile_models = {}\n",
    "val_pred_quantiles = {}\n",
    "\n",
    "for q in quantiles:\n",
    "    print(f\"   Training quantile {q}...\")\n",
    "    \n",
    "    lgb_quantile = lgb.LGBMRegressor(\n",
    "        objective='quantile',\n",
    "        alpha=q,  # quantile parameter\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=200,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    lgb_quantile.fit(X_train_scaled, y_train)\n",
    "    quantile_models[q] = lgb_quantile\n",
    "    val_pred_quantiles[q] = lgb_quantile.predict(X_val_scaled)\n",
    "\n",
    "print(\"âœ… Quantile regression models trained\")\n",
    "print(f\"   Quantiles: {quantiles}\")\n",
    "print(f\"   Provides prediction intervals for uncertainty estimation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82f5f7",
   "metadata": {},
   "source": [
    "#### 5.3.4 Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "print(\"ðŸ”„ Training MLP Model...\")\n",
    "\n",
    "# MLP parameters\n",
    "mlp_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(128, 64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=200,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=15,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Train MLP\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "val_pred_mlp = mlp_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_val, val_pred_mlp))\n",
    "mae = mean_absolute_error(y_val, val_pred_mlp)\n",
    "\n",
    "print(\"âœ… MLP model trained successfully\")\n",
    "print(f\"   Architecture: {mlp_model.hidden_layer_sizes}\")\n",
    "print(f\"   Iterations: {mlp_model.n_iter_}\")\n",
    "print(f\"   Val RMSE: ${rmse:.2f}\")\n",
    "print(f\"   Val MAE: ${mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2393f",
   "metadata": {},
   "source": [
    "### 5.4 Deep Learning Time-Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02df42",
   "metadata": {},
   "source": [
    "**Note:** Deep learning models are implemented using **PyTorch** for better flexibility, performance, and deployment options.\n",
    "\n",
    "**Key Features:**\n",
    "- Custom neural network architectures\n",
    "- GPU acceleration support\n",
    "- Early stopping and learning rate scheduling\n",
    "- Model checkpointing for best weights\n",
    "- Comprehensive training history tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sequences for LSTM/GRU\n",
    "def create_sequences(data, seq_length=60, forecast_horizon=1):\n",
    "    \"\"\"Create input sequences and targets for time-series models\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - forecast_horizon + 1):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length+forecast_horizon-1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Sequence parameters\n",
    "SEQ_LENGTH = 60  # Use 60 days of history\n",
    "FORECAST_HORIZON = 1  # Predict 1 day ahead\n",
    "\n",
    "# Create sequences\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, SEQ_LENGTH, FORECAST_HORIZON)\n",
    "X_val_seq, y_val_seq = create_sequences(X_val_scaled, SEQ_LENGTH, FORECAST_HORIZON)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, SEQ_LENGTH, FORECAST_HORIZON)\n",
    "\n",
    "print(\"ðŸ“Š Sequence Data Prepared:\")\n",
    "print(f\"   Train sequences: {X_train_seq.shape}\")\n",
    "print(f\"   Val sequences: {X_val_seq.shape}\")\n",
    "print(f\"   Test sequences: {X_test_seq.shape}\")\n",
    "print(f\"   Sequence length: {SEQ_LENGTH} days\")\n",
    "print(f\"   Forecast horizon: {FORECAST_HORIZON} day(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86856e67",
   "metadata": {},
   "source": [
    "#### 5.4.1 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "print(\"ðŸ”„ Building LSTM Model...\")\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_torch = torch.FloatTensor(X_train_seq)\n",
    "y_train_torch = torch.FloatTensor(y_train_seq[:, 0]).unsqueeze(1)\n",
    "X_val_torch = torch.FloatTensor(X_val_seq)\n",
    "y_val_torch = torch.FloatTensor(y_val_seq[:, 0]).unsqueeze(1)\n",
    "\n",
    "# Create PyTorch datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "val_dataset = TensorDataset(X_val_torch, y_val_torch)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1=128, hidden_size2=64, hidden_size3=32):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_size1, hidden_size2, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.lstm3 = nn.LSTM(hidden_size2, hidden_size3, batch_first=True)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(hidden_size3, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM layers\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, (h_n, _) = self.lstm3(x)\n",
    "        x = self.dropout3(h_n[-1])  # Use last hidden state\n",
    "        \n",
    "        # Dense layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lstm_model = LSTMModel(input_size=X_train_seq.shape[2]).to(device)\n",
    "\n",
    "print(\"âœ… LSTM architecture built\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "print(\"\\nðŸ”„ Training LSTM...\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 15\n",
    "patience_counter = 0\n",
    "history_lstm = {'train_loss': [], 'val_loss': [], 'val_mae': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    lstm_model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Validation\n",
    "    lstm_model.eval()\n",
    "    val_loss = 0\n",
    "    val_mae = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = lstm_model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_mae += torch.abs(outputs - y_batch).mean().item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_mae /= len(val_loader)\n",
    "    \n",
    "    history_lstm['train_loss'].append(train_loss)\n",
    "    history_lstm['val_loss'].append(val_loss)\n",
    "    history_lstm['val_mae'].append(val_mae)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(lstm_model.state_dict(), 'best_lstm_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"   Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"   Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "lstm_model.load_state_dict(torch.load('best_lstm_model.pth'))\n",
    "\n",
    "# Predictions\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_pred_lstm = lstm_model(X_val_torch.to(device)).cpu().numpy().flatten()\n",
    "\n",
    "print(\"\\nâœ… LSTM training complete\")\n",
    "print(f\"   Final val loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b4404",
   "metadata": {},
   "source": [
    "#### 5.4.2 GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18219e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Building GRU Model...\")\n",
    "\n",
    "# Define GRU Model (often faster than LSTM)\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1=128, hidden_size2=64, hidden_size3=32):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru1 = nn.GRU(input_size, hidden_size1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.gru2 = nn.GRU(hidden_size1, hidden_size2, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.gru3 = nn.GRU(hidden_size2, hidden_size3, batch_first=True)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(hidden_size3, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # GRU layers\n",
    "        x, _ = self.gru1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.gru2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, h_n = self.gru3(x)\n",
    "        x = self.dropout3(h_n[-1])  # Use last hidden state\n",
    "        \n",
    "        # Dense layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "gru_model = GRUModel(input_size=X_train_seq.shape[2]).to(device)\n",
    "\n",
    "print(\"âœ… GRU architecture built\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in gru_model.parameters()):,}\")\n",
    "\n",
    "# Training setup\n",
    "optimizer_gru = optim.Adam(gru_model.parameters(), lr=0.001)\n",
    "scheduler_gru = optim.lr_scheduler.ReduceLROnPlateau(optimizer_gru, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "print(\"\\nðŸ”„ Training GRU...\")\n",
    "\n",
    "# Training loop\n",
    "best_val_loss_gru = float('inf')\n",
    "patience_counter = 0\n",
    "history_gru = {'train_loss': [], 'val_loss': [], 'val_mae': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    gru_model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer_gru.zero_grad()\n",
    "        outputs = gru_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_gru.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Validation\n",
    "    gru_model.eval()\n",
    "    val_loss = 0\n",
    "    val_mae = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = gru_model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_mae += torch.abs(outputs - y_batch).mean().item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_mae /= len(val_loader)\n",
    "    \n",
    "    history_gru['train_loss'].append(train_loss)\n",
    "    history_gru['val_loss'].append(val_loss)\n",
    "    history_gru['val_mae'].append(val_mae)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler_gru.step(val_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss_gru:\n",
    "        best_val_loss_gru = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(gru_model.state_dict(), 'best_gru_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"   Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"   Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "gru_model.load_state_dict(torch.load('best_gru_model.pth'))\n",
    "\n",
    "# Predictions\n",
    "gru_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_pred_gru = gru_model(X_val_torch.to(device)).cpu().numpy().flatten()\n",
    "\n",
    "print(\"\\nâœ… GRU training complete\")\n",
    "print(f\"   Final val loss: {best_val_loss_gru:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab44876",
   "metadata": {},
   "source": [
    "#### 5.4.3 Transformer-based Model (Attention Mechanism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Building Transformer Model with Attention...\")\n",
    "\n",
    "# Define Transformer Model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, d_model=64, nhead=4, num_layers=2, dim_feedforward=128, dropout=0.2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(input_size, d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoder = nn.Parameter(torch.randn(1, SEQ_LENGTH, d_model))\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output layers\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(d_model, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Project input to d_model dimensions\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.pos_encoder\n",
    "        \n",
    "        # Transformer encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = x.transpose(1, 2)  # [batch, d_model, seq_len]\n",
    "        x = self.global_pool(x).squeeze(-1)  # [batch, d_model]\n",
    "        \n",
    "        # Output layers\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "transformer_model = TransformerModel(input_size=X_train_seq.shape[2]).to(device)\n",
    "\n",
    "print(\"âœ… Transformer architecture built\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in transformer_model.parameters()):,}\")\n",
    "\n",
    "# Training setup\n",
    "optimizer_transformer = optim.Adam(transformer_model.parameters(), lr=0.0001)\n",
    "scheduler_transformer = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer_transformer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ”„ Training Transformer...\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs_transformer = 80\n",
    "best_val_loss_transformer = float('inf')\n",
    "patience_counter = 0\n",
    "history_transformer = {'train_loss': [], 'val_loss': [], 'val_mae': []}\n",
    "\n",
    "for epoch in range(num_epochs_transformer):\n",
    "    # Training\n",
    "    transformer_model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer_transformer.zero_grad()\n",
    "        outputs = transformer_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_transformer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Validation\n",
    "    transformer_model.eval()\n",
    "    val_loss = 0\n",
    "    val_mae = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = transformer_model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_mae += torch.abs(outputs - y_batch).mean().item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_mae /= len(val_loader)\n",
    "    \n",
    "    history_transformer['train_loss'].append(train_loss)\n",
    "    history_transformer['val_loss'].append(val_loss)\n",
    "    history_transformer['val_mae'].append(val_mae)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler_transformer.step(val_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss_transformer:\n",
    "        best_val_loss_transformer = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(transformer_model.state_dict(), 'best_transformer_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"   Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"   Epoch {epoch+1}/{num_epochs_transformer} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "transformer_model.load_state_dict(torch.load('best_transformer_model.pth'))\n",
    "\n",
    "# Predictions\n",
    "transformer_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_pred_transformer = transformer_model(X_val_torch.to(device)).cpu().numpy().flatten()\n",
    "\n",
    "print(\"\\nâœ… Transformer training complete\")\n",
    "print(f\"   Final val loss: {best_val_loss_transformer:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce4818",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. MODEL EVALUATION\n",
    "Evaluate model performance and generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b611576",
   "metadata": {},
   "source": [
    "### ðŸ“ˆ Model Evaluation Strategy\n",
    "\n",
    "**Evaluation Framework:**\n",
    "1. **Time-Series Walk-Forward Validation** - Non-leaky, chronological splits\n",
    "2. **Comprehensive Metrics Suite** - Forecast accuracy, directional accuracy, economic metrics\n",
    "3. **Probabilistic Assessment** - Uncertainty quantification and calibration\n",
    "4. **Economic Backtesting** - Transaction costs, slippage, realistic constraints\n",
    "\n",
    "**Metrics Categories:**\n",
    "- **Forecast Accuracy**: RMSE, MAE, MAPE\n",
    "- **Directional Accuracy**: Sign accuracy, precision/recall for up/down signals\n",
    "- **Economic Metrics**: Sharpe ratio, max drawdown, cumulative returns\n",
    "- **Probabilistic**: CRPS, prediction interval coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120401d",
   "metadata": {},
   "source": [
    "### 6.1 Evaluation Metrics Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Percentage Error\"\"\"\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def calculate_directional_accuracy(y_true, y_pred):\n",
    "    \"\"\"Percentage of correct directional predictions\"\"\"\n",
    "    true_direction = np.sign(np.diff(y_true))\n",
    "    pred_direction = np.sign(np.diff(y_pred))\n",
    "    return np.mean(true_direction == pred_direction) * 100\n",
    "\n",
    "def calculate_sharpe_ratio(returns, risk_free_rate=0.02):\n",
    "    \"\"\"Annualized Sharpe Ratio\"\"\"\n",
    "    excess_returns = returns - risk_free_rate / 252  # Daily risk-free rate\n",
    "    if excess_returns.std() == 0:\n",
    "        return 0\n",
    "    return np.sqrt(252) * excess_returns.mean() / excess_returns.std()\n",
    "\n",
    "def calculate_max_drawdown(cumulative_returns):\n",
    "    \"\"\"Maximum Drawdown\"\"\"\n",
    "    running_max = np.maximum.accumulate(cumulative_returns)\n",
    "    drawdown = (cumulative_returns - running_max) / running_max\n",
    "    return drawdown.min() * 100\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    \n",
    "    # Forecast accuracy metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = calculate_mape(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Directional accuracy\n",
    "    dir_acc = calculate_directional_accuracy(y_true, y_pred)\n",
    "    \n",
    "    # Economic metrics (simple strategy: long when predicted price > current)\n",
    "    returns = np.diff(y_true) / y_true[:-1]\n",
    "    pred_signals = np.sign(np.diff(y_pred))\n",
    "    strategy_returns = returns * pred_signals\n",
    "    \n",
    "    # Apply transaction costs (0.1% per trade)\n",
    "    transaction_cost = 0.001\n",
    "    trades = np.sum(np.abs(np.diff(pred_signals)))\n",
    "    strategy_returns_net = strategy_returns - (transaction_cost * trades / len(strategy_returns))\n",
    "    \n",
    "    cumulative_returns = (1 + strategy_returns_net).cumprod()\n",
    "    sharpe = calculate_sharpe_ratio(pd.Series(strategy_returns_net))\n",
    "    max_dd = calculate_max_drawdown(cumulative_returns)\n",
    "    total_return = (cumulative_returns[-1] - 1) * 100\n",
    "    \n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'RÂ²': r2,\n",
    "        'Dir_Accuracy_%': dir_acc,\n",
    "        'Sharpe_Ratio': sharpe,\n",
    "        'Max_Drawdown_%': max_dd,\n",
    "        'Total_Return_%': total_return,\n",
    "        'Num_Trades': trades\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ… Evaluation metrics functions defined\")\n",
    "print(\"   - Forecast accuracy: RMSE, MAE, MAPE, RÂ²\")\n",
    "print(\"   - Directional accuracy: Sign accuracy\")\n",
    "print(\"   - Economic metrics: Sharpe ratio, max drawdown, returns\")\n",
    "print(\"   - Transaction costs included: 0.1% per trade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd28b99",
   "metadata": {},
   "source": [
    "### 6.2 Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Evaluating All Models on Validation Set...\\n\")\n",
    "\n",
    "# Collect all model predictions and evaluate\n",
    "models_results = []\n",
    "\n",
    "# Note: Adjust validation targets based on sequence models\n",
    "y_val_actual = y_val.values\n",
    "y_val_seq_actual = y_val_seq[:, 0]\n",
    "\n",
    "# Classical Models\n",
    "if val_pred_sarimax is not None:\n",
    "    results = evaluate_model(y_val_actual, val_pred_sarimax, 'SARIMAX')\n",
    "    models_results.append(results)\n",
    "    print(f\"âœ“ SARIMAX evaluated\")\n",
    "\n",
    "if val_pred_prophet is not None:\n",
    "    results = evaluate_model(y_val_actual, val_pred_prophet, 'Prophet')\n",
    "    models_results.append(results)\n",
    "    print(f\"âœ“ Prophet evaluated\")\n",
    "\n",
    "# ML Models\n",
    "results = evaluate_model(y_val_actual, val_pred_xgb, 'XGBoost')\n",
    "models_results.append(results)\n",
    "print(f\"âœ“ XGBoost evaluated\")\n",
    "\n",
    "results = evaluate_model(y_val_actual, val_pred_lgb, 'LightGBM')\n",
    "models_results.append(results)\n",
    "print(f\"âœ“ LightGBM evaluated\")\n",
    "\n",
    "results = evaluate_model(y_val_actual, val_pred_mlp, 'MLP')\n",
    "models_results.append(results)\n",
    "print(f\"âœ“ MLP evaluated\")\n",
    "\n",
    "# Deep Learning Models (using sequence-adjusted targets)\n",
    "results = evaluate_model(y_val_seq_actual, val_pred_lstm, 'LSTM')\n",
    "models_results.append(results)\n",
    "print(f\"âœ“ LSTM evaluated\")\n",
    "\n",
    "results = evaluate_model(y_val_seq_actual, val_pred_gru, 'GRU')\n",
    "models_results.append(results)\n",
    "print(f\"âœ“ GRU evaluated\")\n",
    "\n",
    "results = evaluate_model(y_val_seq_actual, val_pred_transformer, 'Transformer')\n",
    "models_results.append(results)\n",
    "print(f\"âœ“ Transformer evaluated\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "results_df = pd.DataFrame(models_results)\n",
    "results_df = results_df.sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ“ˆ MODEL PERFORMANCE COMPARISON (Validation Set)\")\n",
    "print(\"=\"*100)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6dae76",
   "metadata": {},
   "source": [
    "### 6.3 Visualization of Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot predictions vs actual\n",
    "fig, axes = plt.subplots(3, 2, layout = 'constrained',figsize=(16, 12))\n",
    "fig.suptitle('Model Predictions vs Actual (Validation Set)', fontsize=16, fontweight='bold')\n",
    "\n",
    "val_dates = val_df['Date'].values\n",
    "\n",
    "# Helper function for plotting\n",
    "def plot_predictions(ax, actual, pred, model_name, dates):\n",
    "    ax.plot(dates, actual, label='Actual', color='black', linewidth=2, alpha=0.7)\n",
    "    ax.plot(dates, pred, label='Predicted', color='red', linewidth=1.5, alpha=0.7)\n",
    "    ax.set_title(f'{model_name}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price ($)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=55)\n",
    "\n",
    "# Plot each model\n",
    "plot_predictions(axes[0, 0], y_val_actual, val_pred_xgb, 'XGBoost', val_dates)\n",
    "plot_predictions(axes[0, 1], y_val_actual, val_pred_lgb, 'LightGBM', val_dates)\n",
    "plot_predictions(axes[1, 0], y_val_actual, val_pred_mlp, 'MLP', val_dates)\n",
    "\n",
    "# For sequence models, adjust dates\n",
    "val_dates_seq = val_df['Date'].values[SEQ_LENGTH:]\n",
    "plot_predictions(axes[1, 1], y_val_seq_actual, val_pred_lstm, 'LSTM', val_dates_seq)\n",
    "plot_predictions(axes[2, 0], y_val_seq_actual, val_pred_gru, 'GRU', val_dates_seq)\n",
    "plot_predictions(axes[2, 1], y_val_seq_actual, val_pred_transformer, 'Transformer', val_dates_seq)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Prediction visualizations generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d1b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Model Performance Metrics Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0, 0].barh(results_df['Model'], results_df['RMSE'], color='steelblue')\n",
    "axes[0, 0].set_xlabel('RMSE ($)')\n",
    "axes[0, 0].set_title('Root Mean Squared Error (Lower is Better)')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# Directional Accuracy\n",
    "axes[0, 1].barh(results_df['Model'], results_df['Dir_Accuracy_%'], color='green')\n",
    "axes[0, 1].set_xlabel('Directional Accuracy (%)')\n",
    "axes[0, 1].set_title('Directional Accuracy (Higher is Better)')\n",
    "axes[0, 1].invert_yaxis()\n",
    "axes[0, 1].axvline(x=50, color='red', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Sharpe Ratio\n",
    "axes[1, 0].barh(results_df['Model'], results_df['Sharpe_Ratio'], color='orange')\n",
    "axes[1, 0].set_xlabel('Sharpe Ratio')\n",
    "axes[1, 0].set_title('Sharpe Ratio (Higher is Better)')\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Max Drawdown\n",
    "axes[1, 1].barh(results_df['Model'], results_df['Max_Drawdown_%'], color='red')\n",
    "axes[1, 1].set_xlabel('Max Drawdown (%)')\n",
    "axes[1, 1].set_title('Maximum Drawdown (Closer to 0 is Better)')\n",
    "axes[1, 1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Performance metrics visualizations generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9babce0e",
   "metadata": {},
   "source": [
    "### 6.4 Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3c691",
   "metadata": {},
   "source": [
    "#### 6.4.1 Simple Weighted Average Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Creating Weighted Average Ensemble...\")\n",
    "\n",
    "# Calculate weights based on inverse RMSE (better models get higher weights)\n",
    "model_weights = {}\n",
    "total_inv_rmse = 0\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    inv_rmse = 1 / row['RMSE']\n",
    "    model_weights[row['Model']] = inv_rmse\n",
    "    total_inv_rmse += inv_rmse\n",
    "\n",
    "# Normalize weights\n",
    "for model in model_weights:\n",
    "    model_weights[model] /= total_inv_rmse\n",
    "\n",
    "print(\"\\nðŸ“Š Model Weights (based on inverse RMSE):\")\n",
    "for model, weight in sorted(model_weights.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {model:15s}: {weight:.3f} ({weight*100:.1f}%)\")\n",
    "\n",
    "# Create ensemble prediction (only for non-sequence models for simplicity)\n",
    "ensemble_pred_simple = (\n",
    "    val_pred_xgb * model_weights['XGBoost'] +\n",
    "    val_pred_lgb * model_weights['LightGBM'] +\n",
    "    val_pred_mlp * model_weights['MLP']\n",
    ")\n",
    "\n",
    "# Normalize by sum of weights used\n",
    "weight_sum = model_weights['XGBoost'] + model_weights['LightGBM'] + model_weights['MLP']\n",
    "ensemble_pred_simple /= weight_sum\n",
    "\n",
    "# Evaluate ensemble\n",
    "results_ensemble_simple = evaluate_model(y_val_actual, ensemble_pred_simple, 'Ensemble_Weighted')\n",
    "\n",
    "print(\"\\nâœ… Weighted Average Ensemble created\")\n",
    "print(f\"   RMSE: ${results_ensemble_simple['RMSE']:.2f}\")\n",
    "print(f\"   MAE: ${results_ensemble_simple['MAE']:.2f}\")\n",
    "print(f\"   Sharpe Ratio: {results_ensemble_simple['Sharpe_Ratio']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d502b3",
   "metadata": {},
   "source": [
    "#### 6.4.2 Stacking Ensemble (Meta-Learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"ðŸ”„ Creating Stacking Ensemble with Meta-Learner...\")\n",
    "\n",
    "# Prepare meta-features (predictions from base models)\n",
    "meta_features_train = np.column_stack([\n",
    "    xgb_model.predict(X_train_scaled),\n",
    "    lgb_model.predict(X_train_scaled),\n",
    "    mlp_model.predict(X_train_scaled)\n",
    "])\n",
    "\n",
    "meta_features_val = np.column_stack([\n",
    "    val_pred_xgb,\n",
    "    val_pred_lgb,\n",
    "    val_pred_mlp\n",
    "])\n",
    "\n",
    "# Train meta-learner (Ridge regression)\n",
    "meta_learner = Ridge(alpha=1.0)\n",
    "meta_learner.fit(meta_features_train, y_train)\n",
    "\n",
    "# Predict with stacking ensemble\n",
    "ensemble_pred_stack = meta_learner.predict(meta_features_val)\n",
    "\n",
    "# Evaluate stacking ensemble\n",
    "results_ensemble_stack = evaluate_model(y_val_actual, ensemble_pred_stack, 'Ensemble_Stacking')\n",
    "\n",
    "print(\"\\nâœ… Stacking Ensemble created\")\n",
    "print(f\"   Meta-learner: Ridge Regression\")\n",
    "print(f\"   Base models: XGBoost, LightGBM, MLP\")\n",
    "print(f\"   RMSE: ${results_ensemble_stack['RMSE']:.2f}\")\n",
    "print(f\"   MAE: ${results_ensemble_stack['MAE']:.2f}\")\n",
    "print(f\"   Sharpe Ratio: {results_ensemble_stack['Sharpe_Ratio']:.3f}\")\n",
    "\n",
    "# Show meta-learner coefficients\n",
    "print(f\"\\n   Meta-learner coefficients:\")\n",
    "print(f\"      XGBoost: {meta_learner.coef_[0]:.3f}\")\n",
    "print(f\"      LightGBM: {meta_learner.coef_[1]:.3f}\")\n",
    "print(f\"      MLP: {meta_learner.coef_[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48569d",
   "metadata": {},
   "source": [
    "### 6.5 Final Model Comparison with Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a752e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ensemble results to comparison\n",
    "all_results = models_results + [results_ensemble_simple, results_ensemble_stack]\n",
    "final_results_df = pd.DataFrame(all_results)\n",
    "final_results_df = final_results_df.sort_values('RMSE')\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"ðŸ† FINAL MODEL RANKING - ALL MODELS + ENSEMBLES (Validation Set)\")\n",
    "print(\"=\"*120)\n",
    "print(final_results_df.to_string(index=False))\n",
    "print(\"=\"*120)\n",
    "\n",
    "# Highlight best performers\n",
    "print(\"\\nðŸ¥‡ Best Models by Category:\")\n",
    "print(f\"   Lowest RMSE: {final_results_df.iloc[0]['Model']} (${final_results_df.iloc[0]['RMSE']:.2f})\")\n",
    "print(f\"   Best Sharpe: {final_results_df.loc[final_results_df['Sharpe_Ratio'].idxmax()]['Model']} ({final_results_df['Sharpe_Ratio'].max():.3f})\")\n",
    "print(f\"   Best Directional: {final_results_df.loc[final_results_df['Dir_Accuracy_%'].idxmax()]['Model']} ({final_results_df['Dir_Accuracy_%'].max():.1f}%)\")\n",
    "print(f\"   Best Return: {final_results_df.loc[final_results_df['Total_Return_%'].idxmax()]['Model']} ({final_results_df['Total_Return_%'].max():.2f}%)\")\n",
    "\n",
    "# Save results\n",
    "final_results_df.to_csv('../data/processed/model_comparison_results.csv', index=False)\n",
    "print(\"\\nðŸ’¾ Results saved to: ../data/processed/model_comparison_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71383844",
   "metadata": {},
   "source": [
    "### 6.6 Probabilistic Forecasting - Prediction Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Visualizing Prediction Intervals from Quantile Regression...\\n\")\n",
    "\n",
    "# Plot prediction intervals\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Select last 60 days for clarity\n",
    "plot_range = slice(-60, None)\n",
    "dates_plot = val_df['Date'].values[plot_range]\n",
    "actual_plot = y_val_actual[plot_range]\n",
    "\n",
    "# Get quantile predictions for the plot range\n",
    "lower_bound = val_pred_quantiles[0.1][plot_range]\n",
    "median_pred = val_pred_quantiles[0.5][plot_range]\n",
    "upper_bound = val_pred_quantiles[0.9][plot_range]\n",
    "\n",
    "# Plot\n",
    "ax.plot(dates_plot, actual_plot, label='Actual Price', color='black', linewidth=2, marker='o', markersize=3)\n",
    "ax.plot(dates_plot, median_pred, label='Median Prediction (50th)', color='blue', linewidth=2)\n",
    "ax.fill_between(dates_plot, lower_bound, upper_bound, alpha=0.3, color='blue', label='80% Prediction Interval (10th-90th)')\n",
    "\n",
    "ax.set_title('Probabilistic Forecast with Prediction Intervals (Last 60 Days)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Price ($)', fontsize=12)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate coverage (what % of actual values fall within prediction interval)\n",
    "in_interval = (y_val_actual >= val_pred_quantiles[0.1]) & (y_val_actual <= val_pred_quantiles[0.9])\n",
    "coverage = in_interval.mean() * 100\n",
    "\n",
    "print(f\"\\nâœ… Prediction Interval Analysis:\")\n",
    "print(f\"   Target coverage: 80%\")\n",
    "print(f\"   Actual coverage: {coverage:.1f}%\")\n",
    "print(f\"   Well-calibrated: {'Yes âœ“' if 75 <= coverage <= 85 else 'No âœ—'}\")\n",
    "print(f\"\\n   Interpretation: {coverage:.1f}% of actual prices fall within the 10th-90th percentile prediction interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f9ea0",
   "metadata": {},
   "source": [
    "### 6.7 Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ba83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Performing Walk-Forward Validation (Time-Series Cross-Validation)...\\n\")\n",
    "\n",
    "# Walk-forward validation setup\n",
    "n_splits = 5\n",
    "window_size = len(train_df)\n",
    "step_size = len(val_df) // n_splits\n",
    "\n",
    "# Use best model (based on validation) for walk-forward\n",
    "# Let's use LightGBM as example\n",
    "walk_forward_results = []\n",
    "\n",
    "print(f\"   Configuration: {n_splits} splits, window size = {window_size}, step size = {step_size}\\n\")\n",
    "\n",
    "for i in range(n_splits):\n",
    "    start_idx = i * step_size\n",
    "    end_idx = start_idx + step_size\n",
    "    \n",
    "    # Get train and test windows\n",
    "    train_window = df_sorted.iloc[:train_end + start_idx]\n",
    "    test_window = df_sorted.iloc[train_end + start_idx:train_end + end_idx]\n",
    "    \n",
    "    if len(test_window) == 0:\n",
    "        break\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train_wf = train_window[ml_features].fillna(method='ffill').fillna(0)\n",
    "    y_train_wf = train_window[target_col]\n",
    "    X_test_wf = test_window[ml_features].fillna(method='ffill').fillna(0)\n",
    "    y_test_wf = test_window[target_col]\n",
    "    \n",
    "    # Scale\n",
    "    scaler_wf = StandardScaler()\n",
    "    X_train_wf_scaled = scaler_wf.fit_transform(X_train_wf)\n",
    "    X_test_wf_scaled = scaler_wf.transform(X_test_wf)\n",
    "    \n",
    "    # Train model (verbose is set in lgb_params)\n",
    "    lgb_wf = lgb.LGBMRegressor(**lgb_params)\n",
    "    lgb_wf.fit(X_train_wf_scaled, y_train_wf)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_wf = lgb_wf.predict(X_test_wf_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse_wf = np.sqrt(mean_squared_error(y_test_wf, y_pred_wf))\n",
    "    mae_wf = mean_absolute_error(y_test_wf, y_pred_wf)\n",
    "    \n",
    "    walk_forward_results.append({\n",
    "        'Split': i + 1,\n",
    "        'Train_Size': len(train_window),\n",
    "        'Test_Size': len(test_window),\n",
    "        'RMSE': rmse_wf,\n",
    "        'MAE': mae_wf\n",
    "    })\n",
    "    \n",
    "    print(f\"   Split {i+1}/{n_splits}: RMSE=${rmse_wf:.2f}, MAE=${mae_wf:.2f} (Test size: {len(test_window)})\")\n",
    "\n",
    "# Summary\n",
    "wf_df = pd.DataFrame(walk_forward_results)\n",
    "print(\"\\nâœ… Walk-Forward Validation Complete\")\n",
    "print(f\"\\n   Average RMSE: ${wf_df['RMSE'].mean():.2f} (Â±{wf_df['RMSE'].std():.2f})\")\n",
    "print(f\"   Average MAE: ${wf_df['MAE'].mean():.2f} (Â±{wf_df['MAE'].std():.2f})\")\n",
    "print(f\"\\n   This demonstrates model performance across different time periods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b8835",
   "metadata": {},
   "source": [
    "### 6.8 Final Test Set Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58082004",
   "metadata": {},
   "source": [
    "Evaluate all trained models on the final held-out test set to assess real-world performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e49744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL TEST SET EVALUATION - UNSEEN DATA PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nðŸ“Š Test Set Info:\")\n",
    "print(f\"   Size: {len(test_df)} samples\")\n",
    "print(f\"   Date Range: {test_df[date_col].min()} to {test_df[date_col].max()}\")\n",
    "print(f\"   Target: {target_col}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ea0b3",
   "metadata": {},
   "source": [
    "#### 6.8.1 Classical Models Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4dc071",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ” Evaluating Classical Models on Test Set...\\n\")\n",
    "\n",
    "# SARIMAX Test Predictions\n",
    "if val_pred_sarimax is not None:\n",
    "    try:\n",
    "        test_pred_sarimax = sarimax_fit.forecast(steps=len(test_df))\n",
    "        print(\"âœ“ SARIMAX predictions generated\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— SARIMAX failed: {str(e)}\")\n",
    "        test_pred_sarimax = None\n",
    "else:\n",
    "    test_pred_sarimax = None\n",
    "\n",
    "# Prophet Test Predictions\n",
    "if val_pred_prophet is not None:\n",
    "    try:\n",
    "        prophet_test = test_df[[date_col, target_col]].copy()\n",
    "        prophet_test[date_col] = pd.to_datetime(prophet_test[date_col]).dt.tz_localize(None)\n",
    "        prophet_test = prophet_test.rename(columns={date_col: 'ds', target_col: 'y'})\n",
    "        \n",
    "        future_test = prophet_test[['ds']]\n",
    "        forecast_test = prophet_model.predict(future_test)\n",
    "        test_pred_prophet = forecast_test['yhat'].values\n",
    "        print(\"âœ“ Prophet predictions generated\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Prophet failed: {str(e)}\")\n",
    "        test_pred_prophet = None\n",
    "else:\n",
    "    test_pred_prophet = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed09151",
   "metadata": {},
   "source": [
    "#### 6.8.2 Machine Learning Models Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1970fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ” Evaluating ML Models on Test Set...\\n\")\n",
    "\n",
    "# Get test data\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# XGBoost Test Predictions\n",
    "test_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "print(\"âœ“ XGBoost predictions generated\")\n",
    "\n",
    "# LightGBM Test Predictions\n",
    "test_pred_lgb = lgb_model.predict(X_test_scaled)\n",
    "print(\"âœ“ LightGBM predictions generated\")\n",
    "\n",
    "# MLP Test Predictions\n",
    "test_pred_mlp = mlp_model.predict(X_test_scaled)\n",
    "print(\"âœ“ MLP predictions generated\")\n",
    "\n",
    "# Quantile Regression Test Predictions\n",
    "test_pred_quantiles_test = {}\n",
    "for q in quantiles:\n",
    "    test_pred_quantiles_test[q] = quantile_models[q].predict(X_test_scaled)\n",
    "print(\"âœ“ Quantile regression predictions generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107400f",
   "metadata": {},
   "source": [
    "#### 6.8.3 Deep Learning Models Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd75139",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ” Evaluating Deep Learning Models on Test Set...\\n\")\n",
    "\n",
    "# Convert test sequences to PyTorch tensors\n",
    "X_test_torch = torch.FloatTensor(X_test_seq)\n",
    "y_test_seq_target = y_test_seq[:, 0]\n",
    "\n",
    "# LSTM Test Predictions\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred_lstm = lstm_model(X_test_torch.to(device)).cpu().numpy().flatten()\n",
    "print(\"âœ“ LSTM predictions generated\")\n",
    "\n",
    "# GRU Test Predictions\n",
    "gru_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred_gru = gru_model(X_test_torch.to(device)).cpu().numpy().flatten()\n",
    "print(\"âœ“ GRU predictions generated\")\n",
    "\n",
    "# Transformer Test Predictions\n",
    "transformer_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred_transformer = transformer_model(X_test_torch.to(device)).cpu().numpy().flatten()\n",
    "print(\"âœ“ Transformer predictions generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af365d06",
   "metadata": {},
   "source": [
    "#### 6.8.4 Ensemble Model Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829545eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ” Creating Ensemble Predictions on Test Set...\\n\")\n",
    "\n",
    "# Simple Weighted Average Ensemble (using top 3 models)\n",
    "test_pred_ensemble = (\n",
    "    test_pred_xgb * model_weights['XGBoost'] +\n",
    "    test_pred_lgb * model_weights['LightGBM'] +\n",
    "    test_pred_mlp * model_weights['MLP']\n",
    ")\n",
    "\n",
    "# Normalize by sum of weights\n",
    "weight_sum = model_weights['XGBoost'] + model_weights['LightGBM'] + model_weights['MLP']\n",
    "test_pred_ensemble = test_pred_ensemble / weight_sum\n",
    "\n",
    "print(\"âœ“ Ensemble predictions generated\")\n",
    "print(f\"   Ensemble weights: XGBoost={model_weights['XGBoost']:.3f}, LightGBM={model_weights['LightGBM']:.3f}, MLP={model_weights['MLP']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20011c7f",
   "metadata": {},
   "source": [
    "#### 6.8.5 Comprehensive Test Set Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CALCULATING TEST SET METRICS FOR ALL MODELS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Calculate comprehensive metrics for each model\n",
    "def calculate_comprehensive_metrics(y_true, y_pred, model_name):\n",
    "    \"\"\"Calculate all evaluation metrics\"\"\"\n",
    "    try:\n",
    "        # Convert to numpy arrays for consistent handling\n",
    "        y_true_arr = y_true.values if isinstance(y_true, pd.Series) else np.array(y_true)\n",
    "        y_pred_arr = np.array(y_pred)\n",
    "        \n",
    "        # Ensure same length\n",
    "        min_len = min(len(y_true_arr), len(y_pred_arr))\n",
    "        y_true_arr = y_true_arr[:min_len]\n",
    "        y_pred_arr = y_pred_arr[:min_len]\n",
    "        \n",
    "        # Forecast accuracy\n",
    "        rmse = np.sqrt(mean_squared_error(y_true_arr, y_pred_arr))\n",
    "        mae = mean_absolute_error(y_true_arr, y_pred_arr)\n",
    "        mape = np.mean(np.abs((y_true_arr - y_pred_arr) / (y_true_arr + 1e-10))) * 100\n",
    "        \n",
    "        # Directional accuracy (compare direction of change)\n",
    "        if len(y_true_arr) > 1:\n",
    "            actual_direction = (y_true_arr[1:] > y_true_arr[:-1])\n",
    "            pred_direction = (y_pred_arr[1:] > y_pred_arr[:-1])\n",
    "            dir_accuracy = np.mean(actual_direction == pred_direction) * 100\n",
    "        else:\n",
    "            dir_accuracy = 0\n",
    "        \n",
    "        # Economic metrics (simulated trading)\n",
    "        returns = []\n",
    "        for i in range(len(y_pred_arr) - 1):\n",
    "            if y_pred_arr[i+1] > y_pred_arr[i]:  # Predict up\n",
    "                returns.append((y_true_arr[i+1] - y_true_arr[i]) / y_true_arr[i])\n",
    "            else:  # Predict down or flat\n",
    "                returns.append(0)  # Stay in cash\n",
    "        \n",
    "        returns = np.array(returns)\n",
    "        if len(returns) > 0 and np.std(returns) > 0:\n",
    "            sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252)  # Annualized\n",
    "        else:\n",
    "            sharpe_ratio = 0\n",
    "        \n",
    "        # Max drawdown\n",
    "        if len(returns) > 0:\n",
    "            cumulative = np.cumprod(1 + returns)\n",
    "            running_max = np.maximum.accumulate(cumulative)\n",
    "            drawdown = (cumulative - running_max) / running_max\n",
    "            max_drawdown = np.min(drawdown) * 100\n",
    "            cumulative_return = (cumulative[-1] - 1) * 100\n",
    "        else:\n",
    "            max_drawdown = 0\n",
    "            cumulative_return = 0\n",
    "        \n",
    "        return {\n",
    "            'Model': model_name,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MAPE_%': mape,\n",
    "            'Dir_Accuracy_%': dir_accuracy,\n",
    "            'Sharpe_Ratio': sharpe_ratio,\n",
    "            'Max_Drawdown_%': max_drawdown,\n",
    "            'Cumulative_Return_%': cumulative_return\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"âš  Error calculating metrics for {model_name}: {str(e)}\")\n",
    "        return {\n",
    "            'Model': model_name,\n",
    "            'RMSE': np.nan,\n",
    "            'MAE': np.nan,\n",
    "            'MAPE_%': np.nan,\n",
    "            'Dir_Accuracy_%': np.nan,\n",
    "            'Sharpe_Ratio': np.nan,\n",
    "            'Max_Drawdown_%': np.nan,\n",
    "            'Cumulative_Return_%': np.nan\n",
    "        }\n",
    "\n",
    "# Collect all test results\n",
    "test_results = []\n",
    "\n",
    "# Classical Models\n",
    "if test_pred_sarimax is not None:\n",
    "    print(\"   Calculating SARIMAX metrics...\")\n",
    "    test_results.append(calculate_comprehensive_metrics(y_test, test_pred_sarimax, 'SARIMAX'))\n",
    "    \n",
    "if test_pred_prophet is not None:\n",
    "    print(\"   Calculating Prophet metrics...\")\n",
    "    test_results.append(calculate_comprehensive_metrics(y_test, test_pred_prophet, 'Prophet'))\n",
    "\n",
    "# ML Models\n",
    "print(\"   Calculating XGBoost metrics...\")\n",
    "test_results.append(calculate_comprehensive_metrics(y_test, test_pred_xgb, 'XGBoost'))\n",
    "print(\"   Calculating LightGBM metrics...\")\n",
    "test_results.append(calculate_comprehensive_metrics(y_test, test_pred_lgb, 'LightGBM'))\n",
    "print(\"   Calculating MLP metrics...\")\n",
    "test_results.append(calculate_comprehensive_metrics(y_test, test_pred_mlp, 'MLP'))\n",
    "\n",
    "# Deep Learning Models (use sequence targets)\n",
    "print(\"   Calculating LSTM metrics...\")\n",
    "test_results.append(calculate_comprehensive_metrics(y_test_seq_target, test_pred_lstm, 'LSTM'))\n",
    "print(\"   Calculating GRU metrics...\")\n",
    "test_results.append(calculate_comprehensive_metrics(y_test_seq_target, test_pred_gru, 'GRU'))\n",
    "print(\"   Calculating Transformer metrics...\")\n",
    "test_results.append(calculate_comprehensive_metrics(y_test_seq_target, test_pred_transformer, 'Transformer'))\n",
    "\n",
    "# Ensemble\n",
    "print(\"   Calculating Ensemble metrics...\")\n",
    "test_results.append(calculate_comprehensive_metrics(y_test, test_pred_ensemble, 'Ensemble'))\n",
    "\n",
    "# Create DataFrame\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "print(\"\\nâœ… Test set metrics calculated for all models\")\n",
    "print(f\"   Total models evaluated: {len(test_results_df)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a2c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive test results\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL TEST SET PERFORMANCE - ALL MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nðŸ“Š FORECAST ACCURACY METRICS:\\n\")\n",
    "print(test_results_df[['Model', 'RMSE', 'MAE', 'MAPE_%']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nðŸ“ˆ DIRECTIONAL ACCURACY:\\n\")\n",
    "print(test_results_df[['Model', 'Dir_Accuracy_%']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nðŸ’° ECONOMIC METRICS (Simulated Trading):\\n\")\n",
    "print(test_results_df[['Model', 'Sharpe_Ratio', 'Max_Drawdown_%', 'Cumulative_Return_%']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Identify best models\n",
    "print(\"\\nðŸ† BEST PERFORMING MODELS:\\n\")\n",
    "print(f\"   Best RMSE (Accuracy):       {test_results_df.loc[test_results_df['RMSE'].idxmin(), 'Model']} (${test_results_df['RMSE'].min():.2f})\")\n",
    "print(f\"   Best MAE (Accuracy):        {test_results_df.loc[test_results_df['MAE'].idxmin(), 'Model']} (${test_results_df['MAE'].min():.2f})\")\n",
    "print(f\"   Best Directional:           {test_results_df.loc[test_results_df['Dir_Accuracy_%'].idxmax(), 'Model']} ({test_results_df['Dir_Accuracy_%'].max():.2f}%)\")\n",
    "print(f\"   Best Sharpe Ratio:          {test_results_df.loc[test_results_df['Sharpe_Ratio'].idxmax(), 'Model']} ({test_results_df['Sharpe_Ratio'].max():.3f})\")\n",
    "print(f\"   Best Return:                {test_results_df.loc[test_results_df['Cumulative_Return_%'].idxmax(), 'Model']} ({test_results_df['Cumulative_Return_%'].max():.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7a916",
   "metadata": {},
   "source": [
    "#### 6.8.6 Test Set Performance Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test set performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('FINAL TEST SET PERFORMANCE COMPARISON', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Sort by performance\n",
    "test_results_sorted = test_results_df.sort_values('RMSE')\n",
    "\n",
    "# 1. RMSE Comparison\n",
    "axes[0, 0].barh(test_results_sorted['Model'], test_results_sorted['RMSE'], color='steelblue')\n",
    "axes[0, 0].set_xlabel('RMSE ($)', fontsize=11)\n",
    "axes[0, 0].set_title('Forecast Accuracy - RMSE (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].invert_yaxis()\n",
    "axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 2. Directional Accuracy\n",
    "test_results_sorted_dir = test_results_df.sort_values('Dir_Accuracy_%', ascending=False)\n",
    "axes[0, 1].barh(test_results_sorted_dir['Model'], test_results_sorted_dir['Dir_Accuracy_%'], color='green')\n",
    "axes[0, 1].set_xlabel('Directional Accuracy (%)', fontsize=11)\n",
    "axes[0, 1].set_title('Directional Accuracy (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].invert_yaxis()\n",
    "axes[0, 1].axvline(x=50, color='red', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 3. Sharpe Ratio\n",
    "test_results_sorted_sharpe = test_results_df.sort_values('Sharpe_Ratio', ascending=False)\n",
    "axes[1, 0].barh(test_results_sorted_sharpe['Model'], test_results_sorted_sharpe['Sharpe_Ratio'], color='orange')\n",
    "axes[1, 0].set_xlabel('Sharpe Ratio', fontsize=11)\n",
    "axes[1, 0].set_title('Risk-Adjusted Returns - Sharpe Ratio (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Cumulative Return\n",
    "test_results_sorted_return = test_results_df.sort_values('Cumulative_Return_%', ascending=False)\n",
    "colors = ['green' if x > 0 else 'red' for x in test_results_sorted_return['Cumulative_Return_%']]\n",
    "axes[1, 1].barh(test_results_sorted_return['Model'], test_results_sorted_return['Cumulative_Return_%'], color=colors)\n",
    "axes[1, 1].set_xlabel('Cumulative Return (%)', fontsize=11)\n",
    "axes[1, 1].set_title('Simulated Trading Returns (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].invert_yaxis()\n",
    "axes[1, 1].axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Test set performance visualizations generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf81cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual comparison for top models\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "fig.suptitle('TEST SET: PREDICTIONS vs ACTUAL PRICES (Top 3 Models)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Get top 3 models by RMSE\n",
    "top_3_models = test_results_df.nsmallest(3, 'RMSE')['Model'].values\n",
    "\n",
    "# Create test dates for plotting\n",
    "test_dates = test_df[date_col].values if date_col in test_df.columns else range(len(y_test))\n",
    "\n",
    "plot_data = {\n",
    "    'MLP': test_pred_mlp,\n",
    "    'XGBoost': test_pred_xgb,\n",
    "    'LightGBM': test_pred_lgb,\n",
    "    'Ensemble': test_pred_ensemble\n",
    "}\n",
    "\n",
    "# Plot top 3 models\n",
    "for idx, (ax, model_name) in enumerate(zip(axes, ['MLP', 'XGBoost', 'LightGBM'])):\n",
    "    if model_name in plot_data:\n",
    "        ax.plot(test_dates[:100], y_test.values[:100], label='Actual', color='black', linewidth=2, alpha=0.7)\n",
    "        ax.plot(test_dates[:100], plot_data[model_name][:100], label=f'{model_name} Prediction', \n",
    "                color='red', linewidth=1.5, alpha=0.8, linestyle='--')\n",
    "        ax.set_ylabel('Price ($)', fontsize=11)\n",
    "        ax.set_title(f'{model_name} Model - Test Set Predictions (First 100 days)', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add RMSE to plot\n",
    "        model_rmse = test_results_df[test_results_df['Model'] == model_name]['RMSE'].values[0]\n",
    "        ax.text(0.02, 0.98, f'RMSE: ${model_rmse:.2f}', transform=ax.transAxes,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.xlabel('Test Period', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Prediction vs Actual visualizations generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0563fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final test results\n",
    "print(\"\\nðŸ’¾ Saving Test Results...\\n\")\n",
    "\n",
    "# Save results to CSV\n",
    "TEST_RESULTS_PATH = f\"../data/processed/test_results_{STOCK_SYMBOL}.csv\"\n",
    "test_results_df.to_csv(TEST_RESULTS_PATH, index=False)\n",
    "print(f\"âœ“ Test results saved to: {TEST_RESULTS_PATH}\")\n",
    "\n",
    "# Save comparison table\n",
    "COMPARISON_PATH = f\"../data/processed/model_comparison_results.csv\"\n",
    "test_results_df.to_csv(COMPARISON_PATH, index=False)\n",
    "print(f\"âœ“ Model comparison saved to: {COMPARISON_PATH}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nðŸ“Š Test Set Evaluation Complete!\")\n",
    "print(f\"   Period: {test_df[date_col].min()} to {test_df[date_col].max()}\")\n",
    "print(f\"   Samples: {len(test_df)}\")\n",
    "print(f\"   Models Evaluated: {len(test_results_df)}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ RECOMMENDED MODEL FOR PRODUCTION:\")\n",
    "# Recommend based on multiple criteria\n",
    "best_rmse_model = test_results_df.loc[test_results_df['RMSE'].idxmin(), 'Model']\n",
    "best_sharpe_model = test_results_df.loc[test_results_df['Sharpe_Ratio'].idxmax(), 'Model']\n",
    "\n",
    "print(f\"   For Accuracy:        {best_rmse_model}\")\n",
    "print(f\"   For Trading:         {best_sharpe_model}\")\n",
    "print(f\"   For Stability:       Ensemble (combines strengths)\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Next Steps:\")\n",
    "print(f\"   1. Deploy best model(s) to production\")\n",
    "print(f\"   2. Implement real-time data pipeline\")\n",
    "print(f\"   3. Set up monitoring and alerting\")\n",
    "print(f\"   4. Backtest with transaction costs\")\n",
    "print(f\"   5. Paper trade before live deployment\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
